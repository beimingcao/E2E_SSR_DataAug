{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b8f6b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "import os\n",
    "import torch\n",
    "from utils.IO_func import read_file_list, load_binary_file, array_to_binary_file, load_Haskins_SSR_data\n",
    "from shutil import copyfile\n",
    "from utils.transforms import Transform_Compose\n",
    "from utils.transforms import FixMissingValues\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ad631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from comet_ml import Experiment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "498a4a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, D_in = 18, H = 256, D_out = 41, num_layers= 3, bidirectional=False):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.hidden_dim = H\n",
    "        self.num_layers = num_layers\n",
    "        self.num_direction =  2 if bidirectional else 1\n",
    "        self.lstm = nn.LSTM(D_in, H, num_layers, bidirectional=bidirectional)\n",
    "        self.hidden2out = nn.Linear(self.num_direction*self.hidden_dim, D_out)\n",
    "\n",
    "    def init_hidden(self, x):\n",
    "        h, c = (Variable(torch.zeros(self.num_layers * self.num_direction, x.shape[1], self.hidden_dim)),\n",
    "                Variable(torch.zeros(self.num_layers * self.num_direction, x.shape[1], self.hidden_dim)))\n",
    "        return h, c\n",
    "\n",
    "    def forward(self, sequence, h, c):\n",
    "        output, (h, c) = self.lstm(sequence, (h, c))\n",
    "        output = self.hidden2out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4339b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterMeter(object):\n",
    "    \"\"\"keeps track of total iterations\"\"\"\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.val += 1\n",
    "\n",
    "    def get(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a76fde89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "conf_dir = 'conf/SSR_conf.yaml'\n",
    "buff_dir = 'current_exp'\n",
    "\n",
    "config = yaml.load(open(conf_dir, 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "data_path = os.path.join(buff_dir, 'data_CV')\n",
    "SPK_list = ['F01']\n",
    "\n",
    "for test_SPK in SPK_list:\n",
    "    data_path_SPK = os.path.join(data_path, test_SPK)\n",
    "\n",
    "    tr = open(os.path.join(data_path_SPK, 'train_data.pkl'), 'rb') \n",
    "    va = open(os.path.join(data_path_SPK, 'valid_data.pkl'), 'rb')        \n",
    "    train_dataset, valid_dataset = pickle.load(tr), pickle.load(va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c75f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GreedyDecoder(output, labels, label_lengths, blank_label=40, collapse_repeated=True):\n",
    "    \n",
    "    from utils.database import PhoneTransform\n",
    "\n",
    "    text_transform = PhoneTransform()\n",
    "\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "\n",
    "        decode = []\n",
    "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(text_transform.int_to_text(decode))\n",
    "    return decodes, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2190654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(data, transforms = None):\n",
    "    ema = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    \n",
    "    for file_id, x, y in data:\n",
    "        if transforms is not None:\n",
    "            x = transforms(x)\n",
    "\n",
    "        ema.append(torch.FloatTensor(x))\n",
    "        labels.append(y)\n",
    "        input_lengths.append(x.shape[0])\n",
    "        label_lengths.append(len(y))\n",
    "        \n",
    "    ema = torch.nn.utils.rnn.pad_sequence(ema, batch_first=True)\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True)        \n",
    "    \n",
    "    return file_id, ema, labels, input_lengths, label_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a53e89d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=2e-4\n",
    "batch_size=20\n",
    "epochs=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc146ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"n_cnn_layers\": 3,\n",
    "    \"n_rnn_layers\": 3,\n",
    "    \"rnn_dim\": 256,\n",
    "    \"n_class\": 41,\n",
    "    \"n_feats\": 18,\n",
    "    \"stride\": 2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs\n",
    "}\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                            batch_size=1,\n",
    "                            shuffle=True,\n",
    "                            collate_fn=lambda x: data_processing(x, None))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                            batch_size=1,\n",
    "                            shuffle=False,\n",
    "                            collate_fn=lambda x: data_processing(x, None))\n",
    "\n",
    "model = MyLSTM().to(device)\n",
    "\n",
    "#print(model)\n",
    "#print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "criterion = nn.CTCLoss(blank=40).to(device)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
    "                                        steps_per_epoch=int(len(train_loader)),\n",
    "                                        epochs=hparams['epochs'],\n",
    "                                        anneal_strategy='linear')\n",
    "\n",
    "iter_meter = IterMeter()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "899c37ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/1593 (0%)]\tLoss: 21.310196\n",
      "Train Epoch: 0 [100/1593 (6%)]\tLoss: 26.385847\n",
      "Train Epoch: 0 [200/1593 (13%)]\tLoss: 29.046389\n",
      "Train Epoch: 0 [300/1593 (19%)]\tLoss: 21.444120\n",
      "Train Epoch: 0 [400/1593 (25%)]\tLoss: 23.504028\n",
      "Train Epoch: 0 [500/1593 (31%)]\tLoss: 32.984554\n",
      "Train Epoch: 0 [600/1593 (38%)]\tLoss: 24.853695\n",
      "Train Epoch: 0 [700/1593 (44%)]\tLoss: 27.517313\n",
      "Train Epoch: 0 [800/1593 (50%)]\tLoss: 24.818190\n",
      "Train Epoch: 0 [900/1593 (56%)]\tLoss: 24.264030\n",
      "Train Epoch: 0 [1000/1593 (63%)]\tLoss: 14.999396\n",
      "Train Epoch: 0 [1100/1593 (69%)]\tLoss: 19.646482\n",
      "Train Epoch: 0 [1200/1593 (75%)]\tLoss: 11.727869\n",
      "Train Epoch: 0 [1300/1593 (82%)]\tLoss: 9.989902\n",
      "Train Epoch: 0 [1400/1593 (88%)]\tLoss: 6.159327\n",
      "Train Epoch: 0 [1500/1593 (94%)]\tLoss: 4.276491\n",
      "Train Epoch: 1 [0/1593 (0%)]\tLoss: 3.802938\n",
      "Train Epoch: 1 [100/1593 (6%)]\tLoss: 3.601332\n",
      "Train Epoch: 1 [200/1593 (13%)]\tLoss: 3.447984\n",
      "Train Epoch: 1 [300/1593 (19%)]\tLoss: 3.350161\n",
      "Train Epoch: 1 [400/1593 (25%)]\tLoss: 3.540484\n",
      "Train Epoch: 1 [500/1593 (31%)]\tLoss: 3.443237\n",
      "Train Epoch: 1 [600/1593 (38%)]\tLoss: 3.350978\n",
      "Train Epoch: 1 [700/1593 (44%)]\tLoss: 3.534646\n",
      "Train Epoch: 1 [800/1593 (50%)]\tLoss: 3.460700\n",
      "Train Epoch: 1 [900/1593 (56%)]\tLoss: 3.420360\n",
      "Train Epoch: 1 [1000/1593 (63%)]\tLoss: 3.652697\n",
      "Train Epoch: 1 [1100/1593 (69%)]\tLoss: 3.413392\n",
      "Train Epoch: 1 [1200/1593 (75%)]\tLoss: 3.394011\n",
      "Train Epoch: 1 [1300/1593 (82%)]\tLoss: 3.609421\n",
      "Train Epoch: 1 [1400/1593 (88%)]\tLoss: 3.426443\n",
      "Train Epoch: 1 [1500/1593 (94%)]\tLoss: 3.471382\n",
      "Train Epoch: 2 [0/1593 (0%)]\tLoss: 3.392174\n",
      "Train Epoch: 2 [100/1593 (6%)]\tLoss: 3.423573\n",
      "Train Epoch: 2 [200/1593 (13%)]\tLoss: 3.484436\n",
      "Train Epoch: 2 [300/1593 (19%)]\tLoss: 3.706568\n",
      "Train Epoch: 2 [400/1593 (25%)]\tLoss: 3.268698\n",
      "Train Epoch: 2 [500/1593 (31%)]\tLoss: 3.465620\n",
      "Train Epoch: 2 [600/1593 (38%)]\tLoss: 3.406181\n",
      "Train Epoch: 2 [700/1593 (44%)]\tLoss: 3.389518\n",
      "Train Epoch: 2 [800/1593 (50%)]\tLoss: 3.351246\n",
      "Train Epoch: 2 [900/1593 (56%)]\tLoss: 3.354337\n",
      "Train Epoch: 2 [1000/1593 (63%)]\tLoss: 3.442912\n",
      "Train Epoch: 2 [1100/1593 (69%)]\tLoss: 3.314933\n",
      "Train Epoch: 2 [1200/1593 (75%)]\tLoss: 3.578407\n",
      "Train Epoch: 2 [1300/1593 (82%)]\tLoss: 3.573482\n",
      "Train Epoch: 2 [1400/1593 (88%)]\tLoss: 3.580194\n",
      "Train Epoch: 2 [1500/1593 (94%)]\tLoss: 3.461898\n",
      "Train Epoch: 3 [0/1593 (0%)]\tLoss: 3.523497\n",
      "Train Epoch: 3 [100/1593 (6%)]\tLoss: 3.492144\n",
      "Train Epoch: 3 [200/1593 (13%)]\tLoss: 3.546716\n",
      "Train Epoch: 3 [300/1593 (19%)]\tLoss: 3.427287\n",
      "Train Epoch: 3 [400/1593 (25%)]\tLoss: 3.567567\n",
      "Train Epoch: 3 [500/1593 (31%)]\tLoss: 3.469269\n",
      "Train Epoch: 3 [600/1593 (38%)]\tLoss: 3.227399\n",
      "Train Epoch: 3 [700/1593 (44%)]\tLoss: 3.438637\n",
      "Train Epoch: 3 [800/1593 (50%)]\tLoss: 3.694280\n",
      "Train Epoch: 3 [900/1593 (56%)]\tLoss: 3.419244\n",
      "Train Epoch: 3 [1000/1593 (63%)]\tLoss: 3.605413\n",
      "Train Epoch: 3 [1100/1593 (69%)]\tLoss: 3.566879\n",
      "Train Epoch: 3 [1200/1593 (75%)]\tLoss: 3.540843\n",
      "Train Epoch: 3 [1300/1593 (82%)]\tLoss: 3.452891\n",
      "Train Epoch: 3 [1400/1593 (88%)]\tLoss: 3.289943\n",
      "Train Epoch: 3 [1500/1593 (94%)]\tLoss: 3.475551\n",
      "Train Epoch: 4 [0/1593 (0%)]\tLoss: 3.672172\n",
      "Train Epoch: 4 [100/1593 (6%)]\tLoss: 3.295480\n",
      "Train Epoch: 4 [200/1593 (13%)]\tLoss: 3.422575\n",
      "Train Epoch: 4 [300/1593 (19%)]\tLoss: 3.664782\n",
      "Train Epoch: 4 [400/1593 (25%)]\tLoss: 3.504416\n",
      "Train Epoch: 4 [500/1593 (31%)]\tLoss: 3.309999\n",
      "Train Epoch: 4 [600/1593 (38%)]\tLoss: 3.453602\n",
      "Train Epoch: 4 [700/1593 (44%)]\tLoss: 3.370198\n",
      "Train Epoch: 4 [800/1593 (50%)]\tLoss: 3.401602\n",
      "Train Epoch: 4 [900/1593 (56%)]\tLoss: 3.535656\n",
      "Train Epoch: 4 [1000/1593 (63%)]\tLoss: 3.500660\n",
      "Train Epoch: 4 [1100/1593 (69%)]\tLoss: 3.749671\n",
      "Train Epoch: 4 [1200/1593 (75%)]\tLoss: 3.428595\n",
      "Train Epoch: 4 [1300/1593 (82%)]\tLoss: 3.359296\n",
      "Train Epoch: 4 [1400/1593 (88%)]\tLoss: 3.271521\n",
      "Train Epoch: 4 [1500/1593 (94%)]\tLoss: 3.491864\n",
      "Train Epoch: 5 [0/1593 (0%)]\tLoss: 3.274644\n",
      "Train Epoch: 5 [100/1593 (6%)]\tLoss: 3.240468\n",
      "Train Epoch: 5 [200/1593 (13%)]\tLoss: 3.289930\n",
      "Train Epoch: 5 [300/1593 (19%)]\tLoss: 3.570542\n",
      "Train Epoch: 5 [400/1593 (25%)]\tLoss: 3.575531\n",
      "Train Epoch: 5 [500/1593 (31%)]\tLoss: 3.221033\n",
      "Train Epoch: 5 [600/1593 (38%)]\tLoss: 3.285473\n",
      "Train Epoch: 5 [700/1593 (44%)]\tLoss: 3.362975\n",
      "Train Epoch: 5 [800/1593 (50%)]\tLoss: 3.390372\n",
      "Train Epoch: 5 [900/1593 (56%)]\tLoss: 3.703557\n",
      "Train Epoch: 5 [1000/1593 (63%)]\tLoss: 3.631194\n",
      "Train Epoch: 5 [1100/1593 (69%)]\tLoss: 3.466360\n",
      "Train Epoch: 5 [1200/1593 (75%)]\tLoss: 3.344594\n",
      "Train Epoch: 5 [1300/1593 (82%)]\tLoss: 3.443906\n",
      "Train Epoch: 5 [1400/1593 (88%)]\tLoss: 3.310692\n",
      "Train Epoch: 5 [1500/1593 (94%)]\tLoss: 3.662945\n",
      "Train Epoch: 6 [0/1593 (0%)]\tLoss: 3.473042\n",
      "Train Epoch: 6 [100/1593 (6%)]\tLoss: 3.449662\n",
      "Train Epoch: 6 [200/1593 (13%)]\tLoss: 3.314858\n",
      "Train Epoch: 6 [300/1593 (19%)]\tLoss: 3.524434\n",
      "Train Epoch: 6 [400/1593 (25%)]\tLoss: 3.408629\n",
      "Train Epoch: 6 [500/1593 (31%)]\tLoss: 3.490476\n",
      "Train Epoch: 6 [600/1593 (38%)]\tLoss: 3.569718\n",
      "Train Epoch: 6 [700/1593 (44%)]\tLoss: 3.277003\n",
      "Train Epoch: 6 [800/1593 (50%)]\tLoss: 3.320742\n",
      "Train Epoch: 6 [900/1593 (56%)]\tLoss: 3.762524\n",
      "Train Epoch: 6 [1000/1593 (63%)]\tLoss: 3.482174\n",
      "Train Epoch: 6 [1100/1593 (69%)]\tLoss: 3.327595\n",
      "Train Epoch: 6 [1200/1593 (75%)]\tLoss: 3.261545\n",
      "Train Epoch: 6 [1300/1593 (82%)]\tLoss: 3.479902\n",
      "Train Epoch: 6 [1400/1593 (88%)]\tLoss: 3.222354\n",
      "Train Epoch: 6 [1500/1593 (94%)]\tLoss: 3.550553\n",
      "Train Epoch: 7 [0/1593 (0%)]\tLoss: 3.306259\n",
      "Train Epoch: 7 [100/1593 (6%)]\tLoss: 3.309733\n",
      "Train Epoch: 7 [200/1593 (13%)]\tLoss: 3.656055\n",
      "Train Epoch: 7 [300/1593 (19%)]\tLoss: 3.319914\n",
      "Train Epoch: 7 [400/1593 (25%)]\tLoss: 3.556633\n",
      "Train Epoch: 7 [500/1593 (31%)]\tLoss: 3.313797\n",
      "Train Epoch: 7 [600/1593 (38%)]\tLoss: 3.391584\n",
      "Train Epoch: 7 [700/1593 (44%)]\tLoss: 3.682463\n",
      "Train Epoch: 7 [800/1593 (50%)]\tLoss: 3.342671\n",
      "Train Epoch: 7 [900/1593 (56%)]\tLoss: 3.504968\n",
      "Train Epoch: 7 [1000/1593 (63%)]\tLoss: 3.559879\n",
      "Train Epoch: 7 [1100/1593 (69%)]\tLoss: 3.383504\n",
      "Train Epoch: 7 [1200/1593 (75%)]\tLoss: 3.409358\n",
      "Train Epoch: 7 [1300/1593 (82%)]\tLoss: 3.554223\n",
      "Train Epoch: 7 [1400/1593 (88%)]\tLoss: 3.218272\n",
      "Train Epoch: 7 [1500/1593 (94%)]\tLoss: 3.376650\n",
      "Train Epoch: 8 [0/1593 (0%)]\tLoss: 3.459420\n",
      "Train Epoch: 8 [100/1593 (6%)]\tLoss: 3.352162\n",
      "Train Epoch: 8 [200/1593 (13%)]\tLoss: 3.627277\n",
      "Train Epoch: 8 [300/1593 (19%)]\tLoss: 3.420756\n",
      "Train Epoch: 8 [400/1593 (25%)]\tLoss: 3.366162\n",
      "Train Epoch: 8 [500/1593 (31%)]\tLoss: 3.234457\n",
      "Train Epoch: 8 [600/1593 (38%)]\tLoss: 3.647870\n",
      "Train Epoch: 8 [700/1593 (44%)]\tLoss: 3.461735\n",
      "Train Epoch: 8 [800/1593 (50%)]\tLoss: 3.351403\n",
      "Train Epoch: 8 [900/1593 (56%)]\tLoss: 3.275869\n",
      "Train Epoch: 8 [1000/1593 (63%)]\tLoss: 3.466826\n",
      "Train Epoch: 8 [1100/1593 (69%)]\tLoss: 3.105119\n",
      "Train Epoch: 8 [1200/1593 (75%)]\tLoss: 3.490649\n",
      "Train Epoch: 8 [1300/1593 (82%)]\tLoss: 3.534167\n",
      "Train Epoch: 8 [1400/1593 (88%)]\tLoss: 3.432710\n",
      "Train Epoch: 8 [1500/1593 (94%)]\tLoss: 3.533101\n",
      "Train Epoch: 9 [0/1593 (0%)]\tLoss: 3.250591\n",
      "Train Epoch: 9 [100/1593 (6%)]\tLoss: 3.449611\n",
      "Train Epoch: 9 [200/1593 (13%)]\tLoss: 3.418527\n",
      "Train Epoch: 9 [300/1593 (19%)]\tLoss: 3.331620\n",
      "Train Epoch: 9 [400/1593 (25%)]\tLoss: 3.430661\n",
      "Train Epoch: 9 [500/1593 (31%)]\tLoss: 3.387194\n",
      "Train Epoch: 9 [600/1593 (38%)]\tLoss: 3.359144\n",
      "Train Epoch: 9 [700/1593 (44%)]\tLoss: 3.583234\n",
      "Train Epoch: 9 [800/1593 (50%)]\tLoss: 3.137253\n",
      "Train Epoch: 9 [900/1593 (56%)]\tLoss: 3.431180\n",
      "Train Epoch: 9 [1000/1593 (63%)]\tLoss: 3.396486\n",
      "Train Epoch: 9 [1100/1593 (69%)]\tLoss: 3.523949\n",
      "Train Epoch: 9 [1200/1593 (75%)]\tLoss: 3.429609\n",
      "Train Epoch: 9 [1300/1593 (82%)]\tLoss: 3.085234\n",
      "Train Epoch: 9 [1400/1593 (88%)]\tLoss: 3.356902\n",
      "Train Epoch: 9 [1500/1593 (94%)]\tLoss: 3.236477\n",
      "Train Epoch: 10 [0/1593 (0%)]\tLoss: 3.070412\n",
      "Train Epoch: 10 [100/1593 (6%)]\tLoss: 3.096044\n",
      "Train Epoch: 10 [200/1593 (13%)]\tLoss: 3.412599\n",
      "Train Epoch: 10 [300/1593 (19%)]\tLoss: 3.154855\n",
      "Train Epoch: 10 [400/1593 (25%)]\tLoss: 3.175512\n",
      "Train Epoch: 10 [500/1593 (31%)]\tLoss: 3.175220\n",
      "Train Epoch: 10 [600/1593 (38%)]\tLoss: 3.461426\n",
      "Train Epoch: 10 [700/1593 (44%)]\tLoss: 3.158155\n",
      "Train Epoch: 10 [800/1593 (50%)]\tLoss: 3.228117\n",
      "Train Epoch: 10 [900/1593 (56%)]\tLoss: 2.960964\n",
      "Train Epoch: 10 [1000/1593 (63%)]\tLoss: 3.264663\n",
      "Train Epoch: 10 [1100/1593 (69%)]\tLoss: 3.082839\n",
      "Train Epoch: 10 [1200/1593 (75%)]\tLoss: 3.100629\n",
      "Train Epoch: 10 [1300/1593 (82%)]\tLoss: 2.933725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [1400/1593 (88%)]\tLoss: 3.052051\n",
      "Train Epoch: 10 [1500/1593 (94%)]\tLoss: 3.280005\n",
      "Train Epoch: 11 [0/1593 (0%)]\tLoss: 3.361163\n",
      "Train Epoch: 11 [100/1593 (6%)]\tLoss: 3.287887\n",
      "Train Epoch: 11 [200/1593 (13%)]\tLoss: 3.021090\n",
      "Train Epoch: 11 [300/1593 (19%)]\tLoss: 3.280925\n",
      "Train Epoch: 11 [400/1593 (25%)]\tLoss: 3.056537\n",
      "Train Epoch: 11 [500/1593 (31%)]\tLoss: 3.116244\n",
      "Train Epoch: 11 [600/1593 (38%)]\tLoss: 3.293427\n",
      "Train Epoch: 11 [700/1593 (44%)]\tLoss: 3.248296\n",
      "Train Epoch: 11 [800/1593 (50%)]\tLoss: 3.076493\n",
      "Train Epoch: 11 [900/1593 (56%)]\tLoss: 3.450681\n",
      "Train Epoch: 11 [1000/1593 (63%)]\tLoss: 3.423156\n",
      "Train Epoch: 11 [1100/1593 (69%)]\tLoss: 3.207210\n",
      "Train Epoch: 11 [1200/1593 (75%)]\tLoss: 2.896209\n",
      "Train Epoch: 11 [1300/1593 (82%)]\tLoss: 3.479307\n",
      "Train Epoch: 11 [1400/1593 (88%)]\tLoss: 2.818757\n",
      "Train Epoch: 11 [1500/1593 (94%)]\tLoss: 2.768070\n",
      "Train Epoch: 12 [0/1593 (0%)]\tLoss: 2.840521\n",
      "Train Epoch: 12 [100/1593 (6%)]\tLoss: 2.897292\n",
      "Train Epoch: 12 [200/1593 (13%)]\tLoss: 2.842519\n",
      "Train Epoch: 12 [300/1593 (19%)]\tLoss: 2.785922\n",
      "Train Epoch: 12 [400/1593 (25%)]\tLoss: 3.111284\n",
      "Train Epoch: 12 [500/1593 (31%)]\tLoss: 2.791892\n",
      "Train Epoch: 12 [600/1593 (38%)]\tLoss: 2.881709\n",
      "Train Epoch: 12 [700/1593 (44%)]\tLoss: 2.576324\n",
      "Train Epoch: 12 [800/1593 (50%)]\tLoss: 2.846351\n",
      "Train Epoch: 12 [900/1593 (56%)]\tLoss: 2.917826\n",
      "Train Epoch: 12 [1000/1593 (63%)]\tLoss: 2.826054\n",
      "Train Epoch: 12 [1100/1593 (69%)]\tLoss: 2.777346\n",
      "Train Epoch: 12 [1200/1593 (75%)]\tLoss: 2.753450\n",
      "Train Epoch: 12 [1300/1593 (82%)]\tLoss: 2.696163\n",
      "Train Epoch: 12 [1400/1593 (88%)]\tLoss: 2.916716\n",
      "Train Epoch: 12 [1500/1593 (94%)]\tLoss: 2.385216\n",
      "Train Epoch: 13 [0/1593 (0%)]\tLoss: 2.776295\n",
      "Train Epoch: 13 [100/1593 (6%)]\tLoss: 2.652024\n",
      "Train Epoch: 13 [200/1593 (13%)]\tLoss: 2.751837\n",
      "Train Epoch: 13 [300/1593 (19%)]\tLoss: 2.709322\n",
      "Train Epoch: 13 [400/1593 (25%)]\tLoss: 2.723370\n",
      "Train Epoch: 13 [500/1593 (31%)]\tLoss: 2.640956\n",
      "Train Epoch: 13 [600/1593 (38%)]\tLoss: 2.448134\n",
      "Train Epoch: 13 [700/1593 (44%)]\tLoss: 2.497541\n",
      "Train Epoch: 13 [800/1593 (50%)]\tLoss: 2.776283\n",
      "Train Epoch: 13 [900/1593 (56%)]\tLoss: 2.241864\n",
      "Train Epoch: 13 [1000/1593 (63%)]\tLoss: 3.021669\n",
      "Train Epoch: 13 [1100/1593 (69%)]\tLoss: 2.771192\n",
      "Train Epoch: 13 [1200/1593 (75%)]\tLoss: 2.356772\n",
      "Train Epoch: 13 [1300/1593 (82%)]\tLoss: 2.768138\n",
      "Train Epoch: 13 [1400/1593 (88%)]\tLoss: 2.708436\n",
      "Train Epoch: 13 [1500/1593 (94%)]\tLoss: 2.378663\n",
      "Train Epoch: 14 [0/1593 (0%)]\tLoss: 2.416447\n",
      "Train Epoch: 14 [100/1593 (6%)]\tLoss: 2.460495\n",
      "Train Epoch: 14 [200/1593 (13%)]\tLoss: 2.636682\n",
      "Train Epoch: 14 [300/1593 (19%)]\tLoss: 2.266022\n",
      "Train Epoch: 14 [400/1593 (25%)]\tLoss: 2.528027\n",
      "Train Epoch: 14 [500/1593 (31%)]\tLoss: 2.394517\n",
      "Train Epoch: 14 [600/1593 (38%)]\tLoss: 2.479773\n",
      "Train Epoch: 14 [700/1593 (44%)]\tLoss: 2.922117\n",
      "Train Epoch: 14 [800/1593 (50%)]\tLoss: 2.310427\n",
      "Train Epoch: 14 [900/1593 (56%)]\tLoss: 2.489274\n",
      "Train Epoch: 14 [1000/1593 (63%)]\tLoss: 2.572893\n",
      "Train Epoch: 14 [1100/1593 (69%)]\tLoss: 2.624007\n",
      "Train Epoch: 14 [1200/1593 (75%)]\tLoss: 2.820414\n",
      "Train Epoch: 14 [1300/1593 (82%)]\tLoss: 2.562703\n",
      "Train Epoch: 14 [1400/1593 (88%)]\tLoss: 2.166704\n",
      "Train Epoch: 14 [1500/1593 (94%)]\tLoss: 2.376610\n",
      "Train Epoch: 15 [0/1593 (0%)]\tLoss: 2.291097\n",
      "Train Epoch: 15 [100/1593 (6%)]\tLoss: 2.171239\n",
      "Train Epoch: 15 [200/1593 (13%)]\tLoss: 2.696468\n",
      "Train Epoch: 15 [300/1593 (19%)]\tLoss: 2.550503\n",
      "Train Epoch: 15 [400/1593 (25%)]\tLoss: 2.190402\n",
      "Train Epoch: 15 [500/1593 (31%)]\tLoss: 2.480352\n",
      "Train Epoch: 15 [600/1593 (38%)]\tLoss: 2.418382\n",
      "Train Epoch: 15 [700/1593 (44%)]\tLoss: 2.685700\n",
      "Train Epoch: 15 [800/1593 (50%)]\tLoss: 2.857888\n",
      "Train Epoch: 15 [900/1593 (56%)]\tLoss: 2.644964\n",
      "Train Epoch: 15 [1000/1593 (63%)]\tLoss: 2.467595\n",
      "Train Epoch: 15 [1100/1593 (69%)]\tLoss: 2.492596\n",
      "Train Epoch: 15 [1200/1593 (75%)]\tLoss: 2.078198\n",
      "Train Epoch: 15 [1300/1593 (82%)]\tLoss: 2.652289\n",
      "Train Epoch: 15 [1400/1593 (88%)]\tLoss: 2.346505\n",
      "Train Epoch: 15 [1500/1593 (94%)]\tLoss: 2.167042\n",
      "Train Epoch: 16 [0/1593 (0%)]\tLoss: 2.633366\n",
      "Train Epoch: 16 [100/1593 (6%)]\tLoss: 2.359956\n",
      "Train Epoch: 16 [200/1593 (13%)]\tLoss: 2.588981\n",
      "Train Epoch: 16 [300/1593 (19%)]\tLoss: 2.454319\n",
      "Train Epoch: 16 [400/1593 (25%)]\tLoss: 2.222431\n",
      "Train Epoch: 16 [500/1593 (31%)]\tLoss: 2.066434\n",
      "Train Epoch: 16 [600/1593 (38%)]\tLoss: 2.347701\n",
      "Train Epoch: 16 [700/1593 (44%)]\tLoss: 2.055554\n",
      "Train Epoch: 16 [800/1593 (50%)]\tLoss: 2.375399\n",
      "Train Epoch: 16 [900/1593 (56%)]\tLoss: 2.271177\n",
      "Train Epoch: 16 [1000/1593 (63%)]\tLoss: 2.141198\n",
      "Train Epoch: 16 [1100/1593 (69%)]\tLoss: 2.438020\n",
      "Train Epoch: 16 [1200/1593 (75%)]\tLoss: 2.196488\n",
      "Train Epoch: 16 [1300/1593 (82%)]\tLoss: 2.253837\n",
      "Train Epoch: 16 [1400/1593 (88%)]\tLoss: 2.475763\n",
      "Train Epoch: 16 [1500/1593 (94%)]\tLoss: 2.008289\n",
      "Train Epoch: 17 [0/1593 (0%)]\tLoss: 2.244963\n",
      "Train Epoch: 17 [100/1593 (6%)]\tLoss: 2.347111\n",
      "Train Epoch: 17 [200/1593 (13%)]\tLoss: 2.273701\n",
      "Train Epoch: 17 [300/1593 (19%)]\tLoss: 2.315817\n",
      "Train Epoch: 17 [400/1593 (25%)]\tLoss: 2.271569\n",
      "Train Epoch: 17 [500/1593 (31%)]\tLoss: 2.628418\n",
      "Train Epoch: 17 [600/1593 (38%)]\tLoss: 2.304703\n",
      "Train Epoch: 17 [700/1593 (44%)]\tLoss: 2.003340\n",
      "Train Epoch: 17 [800/1593 (50%)]\tLoss: 1.981555\n",
      "Train Epoch: 17 [900/1593 (56%)]\tLoss: 2.305475\n",
      "Train Epoch: 17 [1000/1593 (63%)]\tLoss: 2.336618\n",
      "Train Epoch: 17 [1100/1593 (69%)]\tLoss: 2.328646\n",
      "Train Epoch: 17 [1200/1593 (75%)]\tLoss: 2.082685\n",
      "Train Epoch: 17 [1300/1593 (82%)]\tLoss: 2.267750\n",
      "Train Epoch: 17 [1400/1593 (88%)]\tLoss: 2.244328\n",
      "Train Epoch: 17 [1500/1593 (94%)]\tLoss: 2.058651\n",
      "Train Epoch: 18 [0/1593 (0%)]\tLoss: 2.149069\n",
      "Train Epoch: 18 [100/1593 (6%)]\tLoss: 2.395523\n",
      "Train Epoch: 18 [200/1593 (13%)]\tLoss: 2.159026\n",
      "Train Epoch: 18 [300/1593 (19%)]\tLoss: 2.201646\n",
      "Train Epoch: 18 [400/1593 (25%)]\tLoss: 2.196861\n",
      "Train Epoch: 18 [500/1593 (31%)]\tLoss: 2.197723\n",
      "Train Epoch: 18 [600/1593 (38%)]\tLoss: 2.515181\n",
      "Train Epoch: 18 [700/1593 (44%)]\tLoss: 2.122185\n",
      "Train Epoch: 18 [800/1593 (50%)]\tLoss: 2.047991\n",
      "Train Epoch: 18 [900/1593 (56%)]\tLoss: 2.021461\n",
      "Train Epoch: 18 [1000/1593 (63%)]\tLoss: 2.010745\n",
      "Train Epoch: 18 [1100/1593 (69%)]\tLoss: 2.010770\n",
      "Train Epoch: 18 [1200/1593 (75%)]\tLoss: 2.147363\n",
      "Train Epoch: 18 [1300/1593 (82%)]\tLoss: 2.226514\n",
      "Train Epoch: 18 [1400/1593 (88%)]\tLoss: 2.414759\n",
      "Train Epoch: 18 [1500/1593 (94%)]\tLoss: 2.284878\n",
      "Train Epoch: 19 [0/1593 (0%)]\tLoss: 2.307911\n",
      "Train Epoch: 19 [100/1593 (6%)]\tLoss: 2.412024\n",
      "Train Epoch: 19 [200/1593 (13%)]\tLoss: 1.961283\n",
      "Train Epoch: 19 [300/1593 (19%)]\tLoss: 2.389418\n",
      "Train Epoch: 19 [400/1593 (25%)]\tLoss: 2.174212\n",
      "Train Epoch: 19 [500/1593 (31%)]\tLoss: 2.073610\n",
      "Train Epoch: 19 [600/1593 (38%)]\tLoss: 2.320110\n",
      "Train Epoch: 19 [700/1593 (44%)]\tLoss: 2.060248\n",
      "Train Epoch: 19 [800/1593 (50%)]\tLoss: 2.434537\n",
      "Train Epoch: 19 [900/1593 (56%)]\tLoss: 2.560391\n",
      "Train Epoch: 19 [1000/1593 (63%)]\tLoss: 2.246842\n",
      "Train Epoch: 19 [1100/1593 (69%)]\tLoss: 2.107043\n",
      "Train Epoch: 19 [1200/1593 (75%)]\tLoss: 1.971402\n",
      "Train Epoch: 19 [1300/1593 (82%)]\tLoss: 1.765475\n",
      "Train Epoch: 19 [1400/1593 (88%)]\tLoss: 1.820504\n",
      "Train Epoch: 19 [1500/1593 (94%)]\tLoss: 2.137345\n",
      "Train Epoch: 20 [0/1593 (0%)]\tLoss: 1.879074\n",
      "Train Epoch: 20 [100/1593 (6%)]\tLoss: 2.232986\n",
      "Train Epoch: 20 [200/1593 (13%)]\tLoss: 2.086776\n",
      "Train Epoch: 20 [300/1593 (19%)]\tLoss: 2.591846\n",
      "Train Epoch: 20 [400/1593 (25%)]\tLoss: 2.251687\n",
      "Train Epoch: 20 [500/1593 (31%)]\tLoss: 2.327381\n",
      "Train Epoch: 20 [600/1593 (38%)]\tLoss: 2.170836\n",
      "Train Epoch: 20 [700/1593 (44%)]\tLoss: 2.235110\n",
      "Train Epoch: 20 [800/1593 (50%)]\tLoss: 2.497291\n",
      "Train Epoch: 20 [900/1593 (56%)]\tLoss: 2.122063\n",
      "Train Epoch: 20 [1000/1593 (63%)]\tLoss: 2.162927\n",
      "Train Epoch: 20 [1100/1593 (69%)]\tLoss: 1.942700\n",
      "Train Epoch: 20 [1200/1593 (75%)]\tLoss: 2.035491\n",
      "Train Epoch: 20 [1300/1593 (82%)]\tLoss: 2.121568\n",
      "Train Epoch: 20 [1400/1593 (88%)]\tLoss: 2.240777\n",
      "Train Epoch: 20 [1500/1593 (94%)]\tLoss: 2.381771\n",
      "Train Epoch: 21 [0/1593 (0%)]\tLoss: 1.968913\n",
      "Train Epoch: 21 [100/1593 (6%)]\tLoss: 2.835800\n",
      "Train Epoch: 21 [200/1593 (13%)]\tLoss: 1.971718\n",
      "Train Epoch: 21 [300/1593 (19%)]\tLoss: 2.150991\n",
      "Train Epoch: 21 [400/1593 (25%)]\tLoss: 2.103094\n",
      "Train Epoch: 21 [500/1593 (31%)]\tLoss: 2.349993\n",
      "Train Epoch: 21 [600/1593 (38%)]\tLoss: 2.010885\n",
      "Train Epoch: 21 [700/1593 (44%)]\tLoss: 2.043548\n",
      "Train Epoch: 21 [800/1593 (50%)]\tLoss: 1.654842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 [900/1593 (56%)]\tLoss: 2.143648\n",
      "Train Epoch: 21 [1000/1593 (63%)]\tLoss: 2.110667\n",
      "Train Epoch: 21 [1100/1593 (69%)]\tLoss: 1.952557\n",
      "Train Epoch: 21 [1200/1593 (75%)]\tLoss: 2.087937\n",
      "Train Epoch: 21 [1300/1593 (82%)]\tLoss: 2.157031\n",
      "Train Epoch: 21 [1400/1593 (88%)]\tLoss: 2.077457\n",
      "Train Epoch: 21 [1500/1593 (94%)]\tLoss: 1.945209\n",
      "Train Epoch: 22 [0/1593 (0%)]\tLoss: 2.059566\n",
      "Train Epoch: 22 [100/1593 (6%)]\tLoss: 2.104927\n",
      "Train Epoch: 22 [200/1593 (13%)]\tLoss: 1.695912\n",
      "Train Epoch: 22 [300/1593 (19%)]\tLoss: 1.869347\n",
      "Train Epoch: 22 [400/1593 (25%)]\tLoss: 1.968154\n",
      "Train Epoch: 22 [500/1593 (31%)]\tLoss: 1.969347\n",
      "Train Epoch: 22 [600/1593 (38%)]\tLoss: 1.904996\n",
      "Train Epoch: 22 [700/1593 (44%)]\tLoss: 2.018320\n",
      "Train Epoch: 22 [800/1593 (50%)]\tLoss: 2.541573\n",
      "Train Epoch: 22 [900/1593 (56%)]\tLoss: 2.289386\n",
      "Train Epoch: 22 [1000/1593 (63%)]\tLoss: 2.047191\n",
      "Train Epoch: 22 [1100/1593 (69%)]\tLoss: 1.938551\n",
      "Train Epoch: 22 [1200/1593 (75%)]\tLoss: 1.867007\n",
      "Train Epoch: 22 [1300/1593 (82%)]\tLoss: 1.856459\n",
      "Train Epoch: 22 [1400/1593 (88%)]\tLoss: 1.940642\n",
      "Train Epoch: 22 [1500/1593 (94%)]\tLoss: 2.273466\n",
      "Train Epoch: 23 [0/1593 (0%)]\tLoss: 1.957246\n",
      "Train Epoch: 23 [100/1593 (6%)]\tLoss: 1.932867\n",
      "Train Epoch: 23 [200/1593 (13%)]\tLoss: 1.803703\n",
      "Train Epoch: 23 [300/1593 (19%)]\tLoss: 2.331062\n",
      "Train Epoch: 23 [400/1593 (25%)]\tLoss: 1.822387\n",
      "Train Epoch: 23 [500/1593 (31%)]\tLoss: 2.194974\n",
      "Train Epoch: 23 [600/1593 (38%)]\tLoss: 1.789364\n",
      "Train Epoch: 23 [700/1593 (44%)]\tLoss: 2.315167\n",
      "Train Epoch: 23 [800/1593 (50%)]\tLoss: 1.956429\n",
      "Train Epoch: 23 [900/1593 (56%)]\tLoss: 1.884643\n",
      "Train Epoch: 23 [1000/1593 (63%)]\tLoss: 2.418591\n",
      "Train Epoch: 23 [1100/1593 (69%)]\tLoss: 2.070905\n",
      "Train Epoch: 23 [1200/1593 (75%)]\tLoss: 1.868091\n",
      "Train Epoch: 23 [1300/1593 (82%)]\tLoss: 2.068503\n",
      "Train Epoch: 23 [1400/1593 (88%)]\tLoss: 2.014333\n",
      "Train Epoch: 23 [1500/1593 (94%)]\tLoss: 1.927784\n",
      "Train Epoch: 24 [0/1593 (0%)]\tLoss: 1.895201\n",
      "Train Epoch: 24 [100/1593 (6%)]\tLoss: 2.062532\n",
      "Train Epoch: 24 [200/1593 (13%)]\tLoss: 1.892032\n",
      "Train Epoch: 24 [300/1593 (19%)]\tLoss: 2.090846\n",
      "Train Epoch: 24 [400/1593 (25%)]\tLoss: 1.899599\n",
      "Train Epoch: 24 [500/1593 (31%)]\tLoss: 1.889203\n",
      "Train Epoch: 24 [600/1593 (38%)]\tLoss: 2.107928\n",
      "Train Epoch: 24 [700/1593 (44%)]\tLoss: 1.837317\n",
      "Train Epoch: 24 [800/1593 (50%)]\tLoss: 2.121140\n",
      "Train Epoch: 24 [900/1593 (56%)]\tLoss: 1.824819\n",
      "Train Epoch: 24 [1000/1593 (63%)]\tLoss: 1.701024\n",
      "Train Epoch: 24 [1100/1593 (69%)]\tLoss: 1.926764\n",
      "Train Epoch: 24 [1200/1593 (75%)]\tLoss: 2.068659\n",
      "Train Epoch: 24 [1300/1593 (82%)]\tLoss: 2.209966\n",
      "Train Epoch: 24 [1400/1593 (88%)]\tLoss: 2.699397\n",
      "Train Epoch: 24 [1500/1593 (94%)]\tLoss: 1.881443\n",
      "Train Epoch: 25 [0/1593 (0%)]\tLoss: 1.857532\n",
      "Train Epoch: 25 [100/1593 (6%)]\tLoss: 2.066105\n",
      "Train Epoch: 25 [200/1593 (13%)]\tLoss: 1.873516\n",
      "Train Epoch: 25 [300/1593 (19%)]\tLoss: 1.494047\n",
      "Train Epoch: 25 [400/1593 (25%)]\tLoss: 1.848511\n",
      "Train Epoch: 25 [500/1593 (31%)]\tLoss: 2.105090\n",
      "Train Epoch: 25 [600/1593 (38%)]\tLoss: 1.705582\n",
      "Train Epoch: 25 [700/1593 (44%)]\tLoss: 1.722425\n",
      "Train Epoch: 25 [800/1593 (50%)]\tLoss: 1.947781\n",
      "Train Epoch: 25 [900/1593 (56%)]\tLoss: 2.029564\n",
      "Train Epoch: 25 [1000/1593 (63%)]\tLoss: 1.846731\n",
      "Train Epoch: 25 [1100/1593 (69%)]\tLoss: 1.952199\n",
      "Train Epoch: 25 [1200/1593 (75%)]\tLoss: 2.097993\n",
      "Train Epoch: 25 [1300/1593 (82%)]\tLoss: 2.261342\n",
      "Train Epoch: 25 [1400/1593 (88%)]\tLoss: 1.812806\n",
      "Train Epoch: 25 [1500/1593 (94%)]\tLoss: 2.098315\n",
      "Train Epoch: 26 [0/1593 (0%)]\tLoss: 1.750229\n",
      "Train Epoch: 26 [100/1593 (6%)]\tLoss: 1.809416\n",
      "Train Epoch: 26 [200/1593 (13%)]\tLoss: 1.685736\n",
      "Train Epoch: 26 [300/1593 (19%)]\tLoss: 2.165949\n",
      "Train Epoch: 26 [400/1593 (25%)]\tLoss: 2.272461\n",
      "Train Epoch: 26 [500/1593 (31%)]\tLoss: 2.605751\n",
      "Train Epoch: 26 [600/1593 (38%)]\tLoss: 1.909741\n",
      "Train Epoch: 26 [700/1593 (44%)]\tLoss: 1.811634\n",
      "Train Epoch: 26 [800/1593 (50%)]\tLoss: 1.642418\n",
      "Train Epoch: 26 [900/1593 (56%)]\tLoss: 1.750491\n",
      "Train Epoch: 26 [1000/1593 (63%)]\tLoss: 1.935822\n",
      "Train Epoch: 26 [1100/1593 (69%)]\tLoss: 1.698920\n",
      "Train Epoch: 26 [1200/1593 (75%)]\tLoss: 1.744148\n",
      "Train Epoch: 26 [1300/1593 (82%)]\tLoss: 1.736575\n",
      "Train Epoch: 26 [1400/1593 (88%)]\tLoss: 1.865096\n",
      "Train Epoch: 26 [1500/1593 (94%)]\tLoss: 2.047774\n",
      "Train Epoch: 27 [0/1593 (0%)]\tLoss: 1.688810\n",
      "Train Epoch: 27 [100/1593 (6%)]\tLoss: 2.206989\n",
      "Train Epoch: 27 [200/1593 (13%)]\tLoss: 1.674521\n",
      "Train Epoch: 27 [300/1593 (19%)]\tLoss: 2.224062\n",
      "Train Epoch: 27 [400/1593 (25%)]\tLoss: 1.715207\n",
      "Train Epoch: 27 [500/1593 (31%)]\tLoss: 1.634026\n",
      "Train Epoch: 27 [600/1593 (38%)]\tLoss: 1.511159\n",
      "Train Epoch: 27 [700/1593 (44%)]\tLoss: 1.670509\n",
      "Train Epoch: 27 [800/1593 (50%)]\tLoss: 2.194538\n",
      "Train Epoch: 27 [900/1593 (56%)]\tLoss: 1.795200\n",
      "Train Epoch: 27 [1000/1593 (63%)]\tLoss: 2.294604\n",
      "Train Epoch: 27 [1100/1593 (69%)]\tLoss: 1.677876\n",
      "Train Epoch: 27 [1200/1593 (75%)]\tLoss: 1.852630\n",
      "Train Epoch: 27 [1300/1593 (82%)]\tLoss: 1.999962\n",
      "Train Epoch: 27 [1400/1593 (88%)]\tLoss: 1.628089\n",
      "Train Epoch: 27 [1500/1593 (94%)]\tLoss: 1.706284\n",
      "Train Epoch: 28 [0/1593 (0%)]\tLoss: 2.095628\n",
      "Train Epoch: 28 [100/1593 (6%)]\tLoss: 1.690344\n",
      "Train Epoch: 28 [200/1593 (13%)]\tLoss: 1.830322\n",
      "Train Epoch: 28 [300/1593 (19%)]\tLoss: 1.955776\n",
      "Train Epoch: 28 [400/1593 (25%)]\tLoss: 1.981751\n",
      "Train Epoch: 28 [500/1593 (31%)]\tLoss: 2.006142\n",
      "Train Epoch: 28 [600/1593 (38%)]\tLoss: 2.119007\n",
      "Train Epoch: 28 [700/1593 (44%)]\tLoss: 1.996112\n",
      "Train Epoch: 28 [800/1593 (50%)]\tLoss: 1.457973\n",
      "Train Epoch: 28 [900/1593 (56%)]\tLoss: 2.044439\n",
      "Train Epoch: 28 [1000/1593 (63%)]\tLoss: 1.750152\n",
      "Train Epoch: 28 [1100/1593 (69%)]\tLoss: 1.641579\n",
      "Train Epoch: 28 [1200/1593 (75%)]\tLoss: 1.875250\n",
      "Train Epoch: 28 [1300/1593 (82%)]\tLoss: 2.035543\n",
      "Train Epoch: 28 [1400/1593 (88%)]\tLoss: 2.193343\n",
      "Train Epoch: 28 [1500/1593 (94%)]\tLoss: 1.735394\n",
      "Train Epoch: 29 [0/1593 (0%)]\tLoss: 1.690914\n",
      "Train Epoch: 29 [100/1593 (6%)]\tLoss: 1.766169\n",
      "Train Epoch: 29 [200/1593 (13%)]\tLoss: 1.890228\n",
      "Train Epoch: 29 [300/1593 (19%)]\tLoss: 1.683809\n",
      "Train Epoch: 29 [400/1593 (25%)]\tLoss: 1.777264\n",
      "Train Epoch: 29 [500/1593 (31%)]\tLoss: 1.886549\n",
      "Train Epoch: 29 [600/1593 (38%)]\tLoss: 1.758058\n",
      "Train Epoch: 29 [700/1593 (44%)]\tLoss: 1.980287\n",
      "Train Epoch: 29 [800/1593 (50%)]\tLoss: 1.842803\n",
      "Train Epoch: 29 [900/1593 (56%)]\tLoss: 2.030965\n",
      "Train Epoch: 29 [1000/1593 (63%)]\tLoss: 1.835488\n",
      "Train Epoch: 29 [1100/1593 (69%)]\tLoss: 1.760065\n",
      "Train Epoch: 29 [1200/1593 (75%)]\tLoss: 1.983929\n",
      "Train Epoch: 29 [1300/1593 (82%)]\tLoss: 1.943968\n",
      "Train Epoch: 29 [1400/1593 (88%)]\tLoss: 1.917403\n",
      "Train Epoch: 29 [1500/1593 (94%)]\tLoss: 2.273077\n",
      "Train Epoch: 30 [0/1593 (0%)]\tLoss: 1.883197\n",
      "Train Epoch: 30 [100/1593 (6%)]\tLoss: 1.719793\n",
      "Train Epoch: 30 [200/1593 (13%)]\tLoss: 1.719284\n",
      "Train Epoch: 30 [300/1593 (19%)]\tLoss: 1.610520\n",
      "Train Epoch: 30 [400/1593 (25%)]\tLoss: 1.700522\n",
      "Train Epoch: 30 [500/1593 (31%)]\tLoss: 1.727017\n",
      "Train Epoch: 30 [600/1593 (38%)]\tLoss: 2.178395\n",
      "Train Epoch: 30 [700/1593 (44%)]\tLoss: 2.112153\n",
      "Train Epoch: 30 [800/1593 (50%)]\tLoss: 1.802730\n",
      "Train Epoch: 30 [900/1593 (56%)]\tLoss: 1.759645\n",
      "Train Epoch: 30 [1000/1593 (63%)]\tLoss: 2.153857\n",
      "Train Epoch: 30 [1100/1593 (69%)]\tLoss: 1.639259\n",
      "Train Epoch: 30 [1200/1593 (75%)]\tLoss: 1.748029\n",
      "Train Epoch: 30 [1300/1593 (82%)]\tLoss: 2.087753\n",
      "Train Epoch: 30 [1400/1593 (88%)]\tLoss: 1.781915\n",
      "Train Epoch: 30 [1500/1593 (94%)]\tLoss: 1.842954\n",
      "Train Epoch: 31 [0/1593 (0%)]\tLoss: 1.818185\n",
      "Train Epoch: 31 [100/1593 (6%)]\tLoss: 1.527854\n",
      "Train Epoch: 31 [200/1593 (13%)]\tLoss: 1.737764\n",
      "Train Epoch: 31 [300/1593 (19%)]\tLoss: 2.193916\n",
      "Train Epoch: 31 [400/1593 (25%)]\tLoss: 1.821583\n",
      "Train Epoch: 31 [500/1593 (31%)]\tLoss: 1.659911\n",
      "Train Epoch: 31 [600/1593 (38%)]\tLoss: 1.925992\n",
      "Train Epoch: 31 [700/1593 (44%)]\tLoss: 1.633052\n",
      "Train Epoch: 31 [800/1593 (50%)]\tLoss: 1.988252\n",
      "Train Epoch: 31 [900/1593 (56%)]\tLoss: 1.754604\n",
      "Train Epoch: 31 [1000/1593 (63%)]\tLoss: 2.234218\n",
      "Train Epoch: 31 [1100/1593 (69%)]\tLoss: 2.028091\n",
      "Train Epoch: 31 [1200/1593 (75%)]\tLoss: 1.887403\n",
      "Train Epoch: 31 [1300/1593 (82%)]\tLoss: 1.802867\n",
      "Train Epoch: 31 [1400/1593 (88%)]\tLoss: 2.135974\n",
      "Train Epoch: 31 [1500/1593 (94%)]\tLoss: 1.841902\n",
      "Train Epoch: 32 [0/1593 (0%)]\tLoss: 1.906022\n",
      "Train Epoch: 32 [100/1593 (6%)]\tLoss: 1.832752\n",
      "Train Epoch: 32 [200/1593 (13%)]\tLoss: 1.647620\n",
      "Train Epoch: 32 [300/1593 (19%)]\tLoss: 2.020683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32 [400/1593 (25%)]\tLoss: 1.512898\n",
      "Train Epoch: 32 [500/1593 (31%)]\tLoss: 1.764148\n",
      "Train Epoch: 32 [600/1593 (38%)]\tLoss: 1.556425\n",
      "Train Epoch: 32 [700/1593 (44%)]\tLoss: 1.368546\n",
      "Train Epoch: 32 [800/1593 (50%)]\tLoss: 1.643224\n",
      "Train Epoch: 32 [900/1593 (56%)]\tLoss: 1.965700\n",
      "Train Epoch: 32 [1000/1593 (63%)]\tLoss: 1.945158\n",
      "Train Epoch: 32 [1100/1593 (69%)]\tLoss: 2.030196\n",
      "Train Epoch: 32 [1200/1593 (75%)]\tLoss: 1.666659\n",
      "Train Epoch: 32 [1300/1593 (82%)]\tLoss: 1.812455\n",
      "Train Epoch: 32 [1400/1593 (88%)]\tLoss: 1.498348\n",
      "Train Epoch: 32 [1500/1593 (94%)]\tLoss: 1.702220\n",
      "Train Epoch: 33 [0/1593 (0%)]\tLoss: 1.437135\n",
      "Train Epoch: 33 [100/1593 (6%)]\tLoss: 1.746848\n",
      "Train Epoch: 33 [200/1593 (13%)]\tLoss: 2.206249\n",
      "Train Epoch: 33 [300/1593 (19%)]\tLoss: 1.431959\n",
      "Train Epoch: 33 [400/1593 (25%)]\tLoss: 1.935187\n",
      "Train Epoch: 33 [500/1593 (31%)]\tLoss: 1.639541\n",
      "Train Epoch: 33 [600/1593 (38%)]\tLoss: 2.221561\n",
      "Train Epoch: 33 [700/1593 (44%)]\tLoss: 1.604845\n",
      "Train Epoch: 33 [800/1593 (50%)]\tLoss: 1.754719\n",
      "Train Epoch: 33 [900/1593 (56%)]\tLoss: 1.852821\n",
      "Train Epoch: 33 [1000/1593 (63%)]\tLoss: 1.495372\n",
      "Train Epoch: 33 [1100/1593 (69%)]\tLoss: 1.899976\n",
      "Train Epoch: 33 [1200/1593 (75%)]\tLoss: 1.967453\n",
      "Train Epoch: 33 [1300/1593 (82%)]\tLoss: 1.889160\n",
      "Train Epoch: 33 [1400/1593 (88%)]\tLoss: 1.500096\n",
      "Train Epoch: 33 [1500/1593 (94%)]\tLoss: 1.705045\n",
      "Train Epoch: 34 [0/1593 (0%)]\tLoss: 1.999470\n",
      "Train Epoch: 34 [100/1593 (6%)]\tLoss: 1.941269\n",
      "Train Epoch: 34 [200/1593 (13%)]\tLoss: 1.720348\n",
      "Train Epoch: 34 [300/1593 (19%)]\tLoss: 1.883156\n",
      "Train Epoch: 34 [400/1593 (25%)]\tLoss: 1.618111\n",
      "Train Epoch: 34 [500/1593 (31%)]\tLoss: 1.712483\n",
      "Train Epoch: 34 [600/1593 (38%)]\tLoss: 1.889151\n",
      "Train Epoch: 34 [700/1593 (44%)]\tLoss: 1.510685\n",
      "Train Epoch: 34 [800/1593 (50%)]\tLoss: 1.673726\n",
      "Train Epoch: 34 [900/1593 (56%)]\tLoss: 1.939811\n",
      "Train Epoch: 34 [1000/1593 (63%)]\tLoss: 1.686505\n",
      "Train Epoch: 34 [1100/1593 (69%)]\tLoss: 2.161366\n",
      "Train Epoch: 34 [1200/1593 (75%)]\tLoss: 1.763093\n",
      "Train Epoch: 34 [1300/1593 (82%)]\tLoss: 1.808977\n",
      "Train Epoch: 34 [1400/1593 (88%)]\tLoss: 1.886990\n",
      "Train Epoch: 34 [1500/1593 (94%)]\tLoss: 1.559737\n",
      "Train Epoch: 35 [0/1593 (0%)]\tLoss: 1.825739\n",
      "Train Epoch: 35 [100/1593 (6%)]\tLoss: 2.023015\n",
      "Train Epoch: 35 [200/1593 (13%)]\tLoss: 1.706444\n",
      "Train Epoch: 35 [300/1593 (19%)]\tLoss: 2.005100\n",
      "Train Epoch: 35 [400/1593 (25%)]\tLoss: 1.820869\n",
      "Train Epoch: 35 [500/1593 (31%)]\tLoss: 1.535468\n",
      "Train Epoch: 35 [600/1593 (38%)]\tLoss: 1.686221\n",
      "Train Epoch: 35 [700/1593 (44%)]\tLoss: 1.739011\n",
      "Train Epoch: 35 [800/1593 (50%)]\tLoss: 1.796982\n",
      "Train Epoch: 35 [900/1593 (56%)]\tLoss: 1.551359\n",
      "Train Epoch: 35 [1000/1593 (63%)]\tLoss: 1.817072\n",
      "Train Epoch: 35 [1100/1593 (69%)]\tLoss: 1.575649\n",
      "Train Epoch: 35 [1200/1593 (75%)]\tLoss: 1.863858\n",
      "Train Epoch: 35 [1300/1593 (82%)]\tLoss: 1.736407\n",
      "Train Epoch: 35 [1400/1593 (88%)]\tLoss: 1.819934\n",
      "Train Epoch: 35 [1500/1593 (94%)]\tLoss: 1.597384\n",
      "Train Epoch: 36 [0/1593 (0%)]\tLoss: 1.434175\n",
      "Train Epoch: 36 [100/1593 (6%)]\tLoss: 1.666194\n",
      "Train Epoch: 36 [200/1593 (13%)]\tLoss: 2.038228\n",
      "Train Epoch: 36 [300/1593 (19%)]\tLoss: 1.653994\n",
      "Train Epoch: 36 [400/1593 (25%)]\tLoss: 1.494306\n",
      "Train Epoch: 36 [500/1593 (31%)]\tLoss: 1.808516\n",
      "Train Epoch: 36 [600/1593 (38%)]\tLoss: 1.829603\n",
      "Train Epoch: 36 [700/1593 (44%)]\tLoss: 1.499997\n",
      "Train Epoch: 36 [800/1593 (50%)]\tLoss: 1.992218\n",
      "Train Epoch: 36 [900/1593 (56%)]\tLoss: 1.380910\n",
      "Train Epoch: 36 [1000/1593 (63%)]\tLoss: 1.677933\n",
      "Train Epoch: 36 [1100/1593 (69%)]\tLoss: 1.671863\n",
      "Train Epoch: 36 [1200/1593 (75%)]\tLoss: 1.630703\n",
      "Train Epoch: 36 [1300/1593 (82%)]\tLoss: 1.633545\n",
      "Train Epoch: 36 [1400/1593 (88%)]\tLoss: 1.603938\n",
      "Train Epoch: 36 [1500/1593 (94%)]\tLoss: 1.542513\n",
      "Train Epoch: 37 [0/1593 (0%)]\tLoss: 1.755342\n",
      "Train Epoch: 37 [100/1593 (6%)]\tLoss: 1.738410\n",
      "Train Epoch: 37 [200/1593 (13%)]\tLoss: 1.777666\n",
      "Train Epoch: 37 [300/1593 (19%)]\tLoss: 1.694595\n",
      "Train Epoch: 37 [400/1593 (25%)]\tLoss: 1.566845\n",
      "Train Epoch: 37 [500/1593 (31%)]\tLoss: 1.331475\n",
      "Train Epoch: 37 [600/1593 (38%)]\tLoss: 1.576619\n",
      "Train Epoch: 37 [700/1593 (44%)]\tLoss: 1.929445\n",
      "Train Epoch: 37 [800/1593 (50%)]\tLoss: 1.578974\n",
      "Train Epoch: 37 [900/1593 (56%)]\tLoss: 1.574968\n",
      "Train Epoch: 37 [1000/1593 (63%)]\tLoss: 1.707936\n",
      "Train Epoch: 37 [1100/1593 (69%)]\tLoss: 1.729127\n",
      "Train Epoch: 37 [1200/1593 (75%)]\tLoss: 1.615020\n",
      "Train Epoch: 37 [1300/1593 (82%)]\tLoss: 1.508639\n",
      "Train Epoch: 37 [1400/1593 (88%)]\tLoss: 1.594026\n",
      "Train Epoch: 37 [1500/1593 (94%)]\tLoss: 2.118085\n",
      "Train Epoch: 38 [0/1593 (0%)]\tLoss: 1.827406\n",
      "Train Epoch: 38 [100/1593 (6%)]\tLoss: 1.451444\n",
      "Train Epoch: 38 [200/1593 (13%)]\tLoss: 1.674973\n",
      "Train Epoch: 38 [300/1593 (19%)]\tLoss: 1.573567\n",
      "Train Epoch: 38 [400/1593 (25%)]\tLoss: 1.503761\n",
      "Train Epoch: 38 [500/1593 (31%)]\tLoss: 2.209624\n",
      "Train Epoch: 38 [600/1593 (38%)]\tLoss: 2.183505\n",
      "Train Epoch: 38 [700/1593 (44%)]\tLoss: 1.484102\n",
      "Train Epoch: 38 [800/1593 (50%)]\tLoss: 2.155860\n",
      "Train Epoch: 38 [900/1593 (56%)]\tLoss: 1.574997\n",
      "Train Epoch: 38 [1000/1593 (63%)]\tLoss: 1.884649\n",
      "Train Epoch: 38 [1100/1593 (69%)]\tLoss: 1.940874\n",
      "Train Epoch: 38 [1200/1593 (75%)]\tLoss: 1.605898\n",
      "Train Epoch: 38 [1300/1593 (82%)]\tLoss: 2.294188\n",
      "Train Epoch: 38 [1400/1593 (88%)]\tLoss: 2.395736\n",
      "Train Epoch: 38 [1500/1593 (94%)]\tLoss: 1.453932\n",
      "Train Epoch: 39 [0/1593 (0%)]\tLoss: 2.198078\n",
      "Train Epoch: 39 [100/1593 (6%)]\tLoss: 1.218863\n",
      "Train Epoch: 39 [200/1593 (13%)]\tLoss: 1.793462\n",
      "Train Epoch: 39 [300/1593 (19%)]\tLoss: 1.552903\n",
      "Train Epoch: 39 [400/1593 (25%)]\tLoss: 1.379129\n",
      "Train Epoch: 39 [500/1593 (31%)]\tLoss: 1.925647\n",
      "Train Epoch: 39 [600/1593 (38%)]\tLoss: 2.105345\n",
      "Train Epoch: 39 [700/1593 (44%)]\tLoss: 1.427748\n",
      "Train Epoch: 39 [800/1593 (50%)]\tLoss: 1.530926\n",
      "Train Epoch: 39 [900/1593 (56%)]\tLoss: 1.960652\n",
      "Train Epoch: 39 [1000/1593 (63%)]\tLoss: 1.605661\n",
      "Train Epoch: 39 [1100/1593 (69%)]\tLoss: 1.396736\n",
      "Train Epoch: 39 [1200/1593 (75%)]\tLoss: 1.994688\n",
      "Train Epoch: 39 [1300/1593 (82%)]\tLoss: 2.154164\n",
      "Train Epoch: 39 [1400/1593 (88%)]\tLoss: 1.393890\n",
      "Train Epoch: 39 [1500/1593 (94%)]\tLoss: 1.746938\n",
      "Train Epoch: 40 [0/1593 (0%)]\tLoss: 1.423879\n",
      "Train Epoch: 40 [100/1593 (6%)]\tLoss: 1.403984\n",
      "Train Epoch: 40 [200/1593 (13%)]\tLoss: 2.056103\n",
      "Train Epoch: 40 [300/1593 (19%)]\tLoss: 1.763147\n",
      "Train Epoch: 40 [400/1593 (25%)]\tLoss: 1.741538\n",
      "Train Epoch: 40 [500/1593 (31%)]\tLoss: 1.541672\n",
      "Train Epoch: 40 [600/1593 (38%)]\tLoss: 1.879043\n",
      "Train Epoch: 40 [700/1593 (44%)]\tLoss: 1.737125\n",
      "Train Epoch: 40 [800/1593 (50%)]\tLoss: 2.294155\n",
      "Train Epoch: 40 [900/1593 (56%)]\tLoss: 1.391903\n",
      "Train Epoch: 40 [1000/1593 (63%)]\tLoss: 1.974988\n",
      "Train Epoch: 40 [1100/1593 (69%)]\tLoss: 1.682974\n",
      "Train Epoch: 40 [1200/1593 (75%)]\tLoss: 1.599884\n",
      "Train Epoch: 40 [1300/1593 (82%)]\tLoss: 1.697296\n",
      "Train Epoch: 40 [1400/1593 (88%)]\tLoss: 1.551697\n",
      "Train Epoch: 40 [1500/1593 (94%)]\tLoss: 1.712154\n",
      "Train Epoch: 41 [0/1593 (0%)]\tLoss: 1.737356\n",
      "Train Epoch: 41 [100/1593 (6%)]\tLoss: 2.163073\n",
      "Train Epoch: 41 [200/1593 (13%)]\tLoss: 1.459396\n",
      "Train Epoch: 41 [300/1593 (19%)]\tLoss: 2.088349\n",
      "Train Epoch: 41 [400/1593 (25%)]\tLoss: 1.326008\n",
      "Train Epoch: 41 [500/1593 (31%)]\tLoss: 2.094994\n",
      "Train Epoch: 41 [600/1593 (38%)]\tLoss: 1.240421\n",
      "Train Epoch: 41 [700/1593 (44%)]\tLoss: 2.041158\n",
      "Train Epoch: 41 [800/1593 (50%)]\tLoss: 1.437317\n",
      "Train Epoch: 41 [900/1593 (56%)]\tLoss: 1.875309\n",
      "Train Epoch: 41 [1000/1593 (63%)]\tLoss: 1.824384\n",
      "Train Epoch: 41 [1100/1593 (69%)]\tLoss: 1.600743\n",
      "Train Epoch: 41 [1200/1593 (75%)]\tLoss: 1.874169\n",
      "Train Epoch: 41 [1300/1593 (82%)]\tLoss: 1.295619\n",
      "Train Epoch: 41 [1400/1593 (88%)]\tLoss: 1.489270\n",
      "Train Epoch: 41 [1500/1593 (94%)]\tLoss: 1.273914\n",
      "Train Epoch: 42 [0/1593 (0%)]\tLoss: 1.750954\n",
      "Train Epoch: 42 [100/1593 (6%)]\tLoss: 1.514027\n",
      "Train Epoch: 42 [200/1593 (13%)]\tLoss: 1.648407\n",
      "Train Epoch: 42 [300/1593 (19%)]\tLoss: 2.219615\n",
      "Train Epoch: 42 [400/1593 (25%)]\tLoss: 1.176477\n",
      "Train Epoch: 42 [500/1593 (31%)]\tLoss: 1.935874\n",
      "Train Epoch: 42 [600/1593 (38%)]\tLoss: 1.637126\n",
      "Train Epoch: 42 [700/1593 (44%)]\tLoss: 1.874145\n",
      "Train Epoch: 42 [800/1593 (50%)]\tLoss: 1.539147\n",
      "Train Epoch: 42 [900/1593 (56%)]\tLoss: 1.727866\n",
      "Train Epoch: 42 [1000/1593 (63%)]\tLoss: 1.569062\n",
      "Train Epoch: 42 [1100/1593 (69%)]\tLoss: 1.803068\n",
      "Train Epoch: 42 [1200/1593 (75%)]\tLoss: 1.914135\n",
      "Train Epoch: 42 [1300/1593 (82%)]\tLoss: 1.814224\n",
      "Train Epoch: 42 [1400/1593 (88%)]\tLoss: 1.577750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 42 [1500/1593 (94%)]\tLoss: 1.529582\n",
      "Train Epoch: 43 [0/1593 (0%)]\tLoss: 2.198587\n",
      "Train Epoch: 43 [100/1593 (6%)]\tLoss: 1.876735\n",
      "Train Epoch: 43 [200/1593 (13%)]\tLoss: 1.201084\n",
      "Train Epoch: 43 [300/1593 (19%)]\tLoss: 1.478490\n",
      "Train Epoch: 43 [400/1593 (25%)]\tLoss: 1.873940\n",
      "Train Epoch: 43 [500/1593 (31%)]\tLoss: 1.535146\n",
      "Train Epoch: 43 [600/1593 (38%)]\tLoss: 1.885857\n",
      "Train Epoch: 43 [700/1593 (44%)]\tLoss: 1.530355\n",
      "Train Epoch: 43 [800/1593 (50%)]\tLoss: 1.761753\n",
      "Train Epoch: 43 [900/1593 (56%)]\tLoss: 1.641060\n",
      "Train Epoch: 43 [1000/1593 (63%)]\tLoss: 1.807918\n",
      "Train Epoch: 43 [1100/1593 (69%)]\tLoss: 1.932219\n",
      "Train Epoch: 43 [1200/1593 (75%)]\tLoss: 1.756053\n",
      "Train Epoch: 43 [1300/1593 (82%)]\tLoss: 1.535158\n",
      "Train Epoch: 43 [1400/1593 (88%)]\tLoss: 1.635136\n",
      "Train Epoch: 43 [1500/1593 (94%)]\tLoss: 1.652480\n",
      "Train Epoch: 44 [0/1593 (0%)]\tLoss: 1.625776\n",
      "Train Epoch: 44 [100/1593 (6%)]\tLoss: 1.355201\n",
      "Train Epoch: 44 [200/1593 (13%)]\tLoss: 1.650342\n",
      "Train Epoch: 44 [300/1593 (19%)]\tLoss: 1.579559\n",
      "Train Epoch: 44 [400/1593 (25%)]\tLoss: 2.363941\n",
      "Train Epoch: 44 [500/1593 (31%)]\tLoss: 1.490771\n",
      "Train Epoch: 44 [600/1593 (38%)]\tLoss: 1.510608\n",
      "Train Epoch: 44 [700/1593 (44%)]\tLoss: 1.503551\n",
      "Train Epoch: 44 [800/1593 (50%)]\tLoss: 1.483251\n",
      "Train Epoch: 44 [900/1593 (56%)]\tLoss: 1.859847\n",
      "Train Epoch: 44 [1000/1593 (63%)]\tLoss: 1.470058\n",
      "Train Epoch: 44 [1100/1593 (69%)]\tLoss: 1.486738\n",
      "Train Epoch: 44 [1200/1593 (75%)]\tLoss: 1.615893\n",
      "Train Epoch: 44 [1300/1593 (82%)]\tLoss: 1.810111\n",
      "Train Epoch: 44 [1400/1593 (88%)]\tLoss: 1.584320\n",
      "Train Epoch: 44 [1500/1593 (94%)]\tLoss: 1.451259\n",
      "Train Epoch: 45 [0/1593 (0%)]\tLoss: 1.644331\n",
      "Train Epoch: 45 [100/1593 (6%)]\tLoss: 2.209546\n",
      "Train Epoch: 45 [200/1593 (13%)]\tLoss: 1.730756\n",
      "Train Epoch: 45 [300/1593 (19%)]\tLoss: 1.628001\n",
      "Train Epoch: 45 [400/1593 (25%)]\tLoss: 1.880158\n",
      "Train Epoch: 45 [500/1593 (31%)]\tLoss: 1.803785\n",
      "Train Epoch: 45 [600/1593 (38%)]\tLoss: 1.902850\n",
      "Train Epoch: 45 [700/1593 (44%)]\tLoss: 1.703215\n",
      "Train Epoch: 45 [800/1593 (50%)]\tLoss: 1.653064\n",
      "Train Epoch: 45 [900/1593 (56%)]\tLoss: 1.622749\n",
      "Train Epoch: 45 [1000/1593 (63%)]\tLoss: 1.657322\n",
      "Train Epoch: 45 [1100/1593 (69%)]\tLoss: 1.550240\n",
      "Train Epoch: 45 [1200/1593 (75%)]\tLoss: 1.549221\n",
      "Train Epoch: 45 [1300/1593 (82%)]\tLoss: 1.792986\n",
      "Train Epoch: 45 [1400/1593 (88%)]\tLoss: 1.942755\n",
      "Train Epoch: 45 [1500/1593 (94%)]\tLoss: 1.562137\n",
      "Train Epoch: 46 [0/1593 (0%)]\tLoss: 1.532184\n",
      "Train Epoch: 46 [100/1593 (6%)]\tLoss: 1.595715\n",
      "Train Epoch: 46 [200/1593 (13%)]\tLoss: 1.560463\n",
      "Train Epoch: 46 [300/1593 (19%)]\tLoss: 1.910833\n",
      "Train Epoch: 46 [400/1593 (25%)]\tLoss: 1.814377\n",
      "Train Epoch: 46 [500/1593 (31%)]\tLoss: 1.622993\n",
      "Train Epoch: 46 [600/1593 (38%)]\tLoss: 1.554805\n",
      "Train Epoch: 46 [700/1593 (44%)]\tLoss: 1.639702\n",
      "Train Epoch: 46 [800/1593 (50%)]\tLoss: 1.558756\n",
      "Train Epoch: 46 [900/1593 (56%)]\tLoss: 1.405308\n",
      "Train Epoch: 46 [1000/1593 (63%)]\tLoss: 2.151716\n",
      "Train Epoch: 46 [1100/1593 (69%)]\tLoss: 1.666851\n",
      "Train Epoch: 46 [1200/1593 (75%)]\tLoss: 1.815018\n",
      "Train Epoch: 46 [1300/1593 (82%)]\tLoss: 1.686740\n",
      "Train Epoch: 46 [1400/1593 (88%)]\tLoss: 1.810135\n",
      "Train Epoch: 46 [1500/1593 (94%)]\tLoss: 1.868252\n",
      "Train Epoch: 47 [0/1593 (0%)]\tLoss: 2.032340\n",
      "Train Epoch: 47 [100/1593 (6%)]\tLoss: 1.675788\n",
      "Train Epoch: 47 [200/1593 (13%)]\tLoss: 1.606368\n",
      "Train Epoch: 47 [300/1593 (19%)]\tLoss: 1.815286\n",
      "Train Epoch: 47 [400/1593 (25%)]\tLoss: 1.211874\n",
      "Train Epoch: 47 [500/1593 (31%)]\tLoss: 1.586800\n",
      "Train Epoch: 47 [600/1593 (38%)]\tLoss: 1.249362\n",
      "Train Epoch: 47 [700/1593 (44%)]\tLoss: 1.753556\n",
      "Train Epoch: 47 [800/1593 (50%)]\tLoss: 1.808524\n",
      "Train Epoch: 47 [900/1593 (56%)]\tLoss: 1.551367\n",
      "Train Epoch: 47 [1000/1593 (63%)]\tLoss: 1.591088\n",
      "Train Epoch: 47 [1100/1593 (69%)]\tLoss: 1.523836\n",
      "Train Epoch: 47 [1200/1593 (75%)]\tLoss: 1.496846\n",
      "Train Epoch: 47 [1300/1593 (82%)]\tLoss: 1.503811\n",
      "Train Epoch: 47 [1400/1593 (88%)]\tLoss: 1.970014\n",
      "Train Epoch: 47 [1500/1593 (94%)]\tLoss: 1.421927\n",
      "Train Epoch: 48 [0/1593 (0%)]\tLoss: 1.509962\n",
      "Train Epoch: 48 [100/1593 (6%)]\tLoss: 1.572487\n",
      "Train Epoch: 48 [200/1593 (13%)]\tLoss: 1.112070\n",
      "Train Epoch: 48 [300/1593 (19%)]\tLoss: 1.834368\n",
      "Train Epoch: 48 [400/1593 (25%)]\tLoss: 1.437126\n",
      "Train Epoch: 48 [500/1593 (31%)]\tLoss: 1.605409\n",
      "Train Epoch: 48 [600/1593 (38%)]\tLoss: 1.593440\n",
      "Train Epoch: 48 [700/1593 (44%)]\tLoss: 1.619426\n",
      "Train Epoch: 48 [800/1593 (50%)]\tLoss: 2.008699\n",
      "Train Epoch: 48 [900/1593 (56%)]\tLoss: 1.465165\n",
      "Train Epoch: 48 [1000/1593 (63%)]\tLoss: 1.756217\n",
      "Train Epoch: 48 [1100/1593 (69%)]\tLoss: 1.664830\n",
      "Train Epoch: 48 [1200/1593 (75%)]\tLoss: 1.451448\n",
      "Train Epoch: 48 [1300/1593 (82%)]\tLoss: 2.398401\n",
      "Train Epoch: 48 [1400/1593 (88%)]\tLoss: 1.532164\n",
      "Train Epoch: 48 [1500/1593 (94%)]\tLoss: 1.866803\n",
      "Train Epoch: 49 [0/1593 (0%)]\tLoss: 1.560596\n",
      "Train Epoch: 49 [100/1593 (6%)]\tLoss: 1.509084\n",
      "Train Epoch: 49 [200/1593 (13%)]\tLoss: 1.964645\n",
      "Train Epoch: 49 [300/1593 (19%)]\tLoss: 1.703228\n",
      "Train Epoch: 49 [400/1593 (25%)]\tLoss: 1.654309\n",
      "Train Epoch: 49 [500/1593 (31%)]\tLoss: 1.581987\n",
      "Train Epoch: 49 [600/1593 (38%)]\tLoss: 1.718415\n",
      "Train Epoch: 49 [700/1593 (44%)]\tLoss: 1.565914\n",
      "Train Epoch: 49 [800/1593 (50%)]\tLoss: 1.644436\n",
      "Train Epoch: 49 [900/1593 (56%)]\tLoss: 2.217197\n",
      "Train Epoch: 49 [1000/1593 (63%)]\tLoss: 1.776273\n",
      "Train Epoch: 49 [1100/1593 (69%)]\tLoss: 1.576892\n",
      "Train Epoch: 49 [1200/1593 (75%)]\tLoss: 1.604678\n",
      "Train Epoch: 49 [1300/1593 (82%)]\tLoss: 1.646871\n",
      "Train Epoch: 49 [1400/1593 (88%)]\tLoss: 1.637737\n",
      "Train Epoch: 49 [1500/1593 (94%)]\tLoss: 1.799109\n",
      "Train Epoch: 50 [0/1593 (0%)]\tLoss: 1.667265\n",
      "Train Epoch: 50 [100/1593 (6%)]\tLoss: 1.615124\n",
      "Train Epoch: 50 [200/1593 (13%)]\tLoss: 1.432367\n",
      "Train Epoch: 50 [300/1593 (19%)]\tLoss: 1.634606\n",
      "Train Epoch: 50 [400/1593 (25%)]\tLoss: 1.457001\n",
      "Train Epoch: 50 [500/1593 (31%)]\tLoss: 1.335592\n",
      "Train Epoch: 50 [600/1593 (38%)]\tLoss: 1.555690\n",
      "Train Epoch: 50 [700/1593 (44%)]\tLoss: 1.534090\n",
      "Train Epoch: 50 [800/1593 (50%)]\tLoss: 1.443054\n",
      "Train Epoch: 50 [900/1593 (56%)]\tLoss: 1.860122\n",
      "Train Epoch: 50 [1000/1593 (63%)]\tLoss: 1.871153\n",
      "Train Epoch: 50 [1100/1593 (69%)]\tLoss: 1.452873\n",
      "Train Epoch: 50 [1200/1593 (75%)]\tLoss: 1.500251\n",
      "Train Epoch: 50 [1300/1593 (82%)]\tLoss: 1.646222\n",
      "Train Epoch: 50 [1400/1593 (88%)]\tLoss: 1.835102\n",
      "Train Epoch: 50 [1500/1593 (94%)]\tLoss: 1.160194\n",
      "Train Epoch: 51 [0/1593 (0%)]\tLoss: 1.423868\n",
      "Train Epoch: 51 [100/1593 (6%)]\tLoss: 1.636934\n",
      "Train Epoch: 51 [200/1593 (13%)]\tLoss: 1.735755\n",
      "Train Epoch: 51 [300/1593 (19%)]\tLoss: 1.616261\n",
      "Train Epoch: 51 [400/1593 (25%)]\tLoss: 1.418741\n",
      "Train Epoch: 51 [500/1593 (31%)]\tLoss: 1.269145\n",
      "Train Epoch: 51 [600/1593 (38%)]\tLoss: 1.457093\n",
      "Train Epoch: 51 [700/1593 (44%)]\tLoss: 1.352870\n",
      "Train Epoch: 51 [800/1593 (50%)]\tLoss: 1.403293\n",
      "Train Epoch: 51 [900/1593 (56%)]\tLoss: 1.786056\n",
      "Train Epoch: 51 [1000/1593 (63%)]\tLoss: 1.533617\n",
      "Train Epoch: 51 [1100/1593 (69%)]\tLoss: 2.104880\n",
      "Train Epoch: 51 [1200/1593 (75%)]\tLoss: 1.096034\n",
      "Train Epoch: 51 [1300/1593 (82%)]\tLoss: 1.484122\n",
      "Train Epoch: 51 [1400/1593 (88%)]\tLoss: 1.697936\n",
      "Train Epoch: 51 [1500/1593 (94%)]\tLoss: 1.702298\n",
      "Train Epoch: 52 [0/1593 (0%)]\tLoss: 1.437387\n",
      "Train Epoch: 52 [100/1593 (6%)]\tLoss: 1.777521\n",
      "Train Epoch: 52 [200/1593 (13%)]\tLoss: 1.391015\n",
      "Train Epoch: 52 [300/1593 (19%)]\tLoss: 1.702938\n",
      "Train Epoch: 52 [400/1593 (25%)]\tLoss: 1.494411\n",
      "Train Epoch: 52 [500/1593 (31%)]\tLoss: 1.772782\n",
      "Train Epoch: 52 [600/1593 (38%)]\tLoss: 1.564716\n",
      "Train Epoch: 52 [700/1593 (44%)]\tLoss: 1.594038\n",
      "Train Epoch: 52 [800/1593 (50%)]\tLoss: 2.104375\n",
      "Train Epoch: 52 [900/1593 (56%)]\tLoss: 1.108248\n",
      "Train Epoch: 52 [1000/1593 (63%)]\tLoss: 1.644464\n",
      "Train Epoch: 52 [1100/1593 (69%)]\tLoss: 1.699930\n",
      "Train Epoch: 52 [1200/1593 (75%)]\tLoss: 1.394299\n",
      "Train Epoch: 52 [1300/1593 (82%)]\tLoss: 1.795407\n",
      "Train Epoch: 52 [1400/1593 (88%)]\tLoss: 2.415828\n",
      "Train Epoch: 52 [1500/1593 (94%)]\tLoss: 1.658615\n",
      "Train Epoch: 53 [0/1593 (0%)]\tLoss: 1.373184\n",
      "Train Epoch: 53 [100/1593 (6%)]\tLoss: 1.464303\n",
      "Train Epoch: 53 [200/1593 (13%)]\tLoss: 1.623713\n",
      "Train Epoch: 53 [300/1593 (19%)]\tLoss: 1.228750\n",
      "Train Epoch: 53 [400/1593 (25%)]\tLoss: 1.643237\n",
      "Train Epoch: 53 [500/1593 (31%)]\tLoss: 1.971086\n",
      "Train Epoch: 53 [600/1593 (38%)]\tLoss: 1.351467\n",
      "Train Epoch: 53 [700/1593 (44%)]\tLoss: 1.864812\n",
      "Train Epoch: 53 [800/1593 (50%)]\tLoss: 1.724752\n",
      "Train Epoch: 53 [900/1593 (56%)]\tLoss: 1.804278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 53 [1000/1593 (63%)]\tLoss: 1.526792\n",
      "Train Epoch: 53 [1100/1593 (69%)]\tLoss: 1.624243\n",
      "Train Epoch: 53 [1200/1593 (75%)]\tLoss: 1.445471\n",
      "Train Epoch: 53 [1300/1593 (82%)]\tLoss: 1.738680\n",
      "Train Epoch: 53 [1400/1593 (88%)]\tLoss: 1.484964\n",
      "Train Epoch: 53 [1500/1593 (94%)]\tLoss: 1.893504\n",
      "Train Epoch: 54 [0/1593 (0%)]\tLoss: 1.215502\n",
      "Train Epoch: 54 [100/1593 (6%)]\tLoss: 1.522900\n",
      "Train Epoch: 54 [200/1593 (13%)]\tLoss: 1.484900\n",
      "Train Epoch: 54 [300/1593 (19%)]\tLoss: 1.474905\n",
      "Train Epoch: 54 [400/1593 (25%)]\tLoss: 1.338569\n",
      "Train Epoch: 54 [500/1593 (31%)]\tLoss: 1.353220\n",
      "Train Epoch: 54 [600/1593 (38%)]\tLoss: 1.610574\n",
      "Train Epoch: 54 [700/1593 (44%)]\tLoss: 2.036650\n",
      "Train Epoch: 54 [800/1593 (50%)]\tLoss: 1.478721\n",
      "Train Epoch: 54 [900/1593 (56%)]\tLoss: 1.547753\n",
      "Train Epoch: 54 [1000/1593 (63%)]\tLoss: 1.625532\n",
      "Train Epoch: 54 [1100/1593 (69%)]\tLoss: 1.376763\n",
      "Train Epoch: 54 [1200/1593 (75%)]\tLoss: 2.113838\n",
      "Train Epoch: 54 [1300/1593 (82%)]\tLoss: 1.172675\n",
      "Train Epoch: 54 [1400/1593 (88%)]\tLoss: 1.295416\n",
      "Train Epoch: 54 [1500/1593 (94%)]\tLoss: 1.912597\n",
      "Train Epoch: 55 [0/1593 (0%)]\tLoss: 1.529323\n",
      "Train Epoch: 55 [100/1593 (6%)]\tLoss: 1.645460\n",
      "Train Epoch: 55 [200/1593 (13%)]\tLoss: 1.438372\n",
      "Train Epoch: 55 [300/1593 (19%)]\tLoss: 1.448290\n",
      "Train Epoch: 55 [400/1593 (25%)]\tLoss: 1.655222\n",
      "Train Epoch: 55 [500/1593 (31%)]\tLoss: 1.501642\n",
      "Train Epoch: 55 [600/1593 (38%)]\tLoss: 1.431662\n",
      "Train Epoch: 55 [700/1593 (44%)]\tLoss: 1.545294\n",
      "Train Epoch: 55 [800/1593 (50%)]\tLoss: 1.552191\n",
      "Train Epoch: 55 [900/1593 (56%)]\tLoss: 1.301383\n",
      "Train Epoch: 55 [1000/1593 (63%)]\tLoss: 1.573439\n",
      "Train Epoch: 55 [1100/1593 (69%)]\tLoss: 1.346835\n",
      "Train Epoch: 55 [1200/1593 (75%)]\tLoss: 1.663127\n",
      "Train Epoch: 55 [1300/1593 (82%)]\tLoss: 1.586990\n",
      "Train Epoch: 55 [1400/1593 (88%)]\tLoss: 1.995197\n",
      "Train Epoch: 55 [1500/1593 (94%)]\tLoss: 1.559578\n",
      "Train Epoch: 56 [0/1593 (0%)]\tLoss: 1.874779\n",
      "Train Epoch: 56 [100/1593 (6%)]\tLoss: 1.637561\n",
      "Train Epoch: 56 [200/1593 (13%)]\tLoss: 1.886755\n",
      "Train Epoch: 56 [300/1593 (19%)]\tLoss: 1.706783\n",
      "Train Epoch: 56 [400/1593 (25%)]\tLoss: 1.629934\n",
      "Train Epoch: 56 [500/1593 (31%)]\tLoss: 1.726994\n",
      "Train Epoch: 56 [600/1593 (38%)]\tLoss: 1.638772\n",
      "Train Epoch: 56 [700/1593 (44%)]\tLoss: 1.376720\n",
      "Train Epoch: 56 [800/1593 (50%)]\tLoss: 1.579940\n",
      "Train Epoch: 56 [900/1593 (56%)]\tLoss: 1.212972\n",
      "Train Epoch: 56 [1000/1593 (63%)]\tLoss: 1.657044\n",
      "Train Epoch: 56 [1100/1593 (69%)]\tLoss: 1.743862\n",
      "Train Epoch: 56 [1200/1593 (75%)]\tLoss: 1.696371\n",
      "Train Epoch: 56 [1300/1593 (82%)]\tLoss: 1.265800\n",
      "Train Epoch: 56 [1400/1593 (88%)]\tLoss: 1.572153\n",
      "Train Epoch: 56 [1500/1593 (94%)]\tLoss: 1.533401\n",
      "Train Epoch: 57 [0/1593 (0%)]\tLoss: 1.341807\n",
      "Train Epoch: 57 [100/1593 (6%)]\tLoss: 1.806094\n",
      "Train Epoch: 57 [200/1593 (13%)]\tLoss: 1.434965\n",
      "Train Epoch: 57 [300/1593 (19%)]\tLoss: 1.716479\n",
      "Train Epoch: 57 [400/1593 (25%)]\tLoss: 1.596587\n",
      "Train Epoch: 57 [500/1593 (31%)]\tLoss: 1.409435\n",
      "Train Epoch: 57 [600/1593 (38%)]\tLoss: 1.393404\n",
      "Train Epoch: 57 [700/1593 (44%)]\tLoss: 2.089658\n",
      "Train Epoch: 57 [800/1593 (50%)]\tLoss: 1.321602\n",
      "Train Epoch: 57 [900/1593 (56%)]\tLoss: 1.767546\n",
      "Train Epoch: 57 [1000/1593 (63%)]\tLoss: 2.008954\n",
      "Train Epoch: 57 [1100/1593 (69%)]\tLoss: 1.704454\n",
      "Train Epoch: 57 [1200/1593 (75%)]\tLoss: 1.907655\n",
      "Train Epoch: 57 [1300/1593 (82%)]\tLoss: 1.603538\n",
      "Train Epoch: 57 [1400/1593 (88%)]\tLoss: 1.200835\n",
      "Train Epoch: 57 [1500/1593 (94%)]\tLoss: 1.477772\n",
      "Train Epoch: 58 [0/1593 (0%)]\tLoss: 1.260107\n",
      "Train Epoch: 58 [100/1593 (6%)]\tLoss: 2.269816\n",
      "Train Epoch: 58 [200/1593 (13%)]\tLoss: 1.554444\n",
      "Train Epoch: 58 [300/1593 (19%)]\tLoss: 1.396216\n",
      "Train Epoch: 58 [400/1593 (25%)]\tLoss: 1.499300\n",
      "Train Epoch: 58 [500/1593 (31%)]\tLoss: 1.756432\n",
      "Train Epoch: 58 [600/1593 (38%)]\tLoss: 1.132974\n",
      "Train Epoch: 58 [700/1593 (44%)]\tLoss: 1.550178\n",
      "Train Epoch: 58 [800/1593 (50%)]\tLoss: 1.413275\n",
      "Train Epoch: 58 [900/1593 (56%)]\tLoss: 1.280554\n",
      "Train Epoch: 58 [1000/1593 (63%)]\tLoss: 1.000878\n",
      "Train Epoch: 58 [1100/1593 (69%)]\tLoss: 1.500148\n",
      "Train Epoch: 58 [1200/1593 (75%)]\tLoss: 1.335311\n",
      "Train Epoch: 58 [1300/1593 (82%)]\tLoss: 1.749067\n",
      "Train Epoch: 58 [1400/1593 (88%)]\tLoss: 1.829891\n",
      "Train Epoch: 58 [1500/1593 (94%)]\tLoss: 1.372136\n",
      "Train Epoch: 59 [0/1593 (0%)]\tLoss: 1.576263\n",
      "Train Epoch: 59 [100/1593 (6%)]\tLoss: 1.947929\n",
      "Train Epoch: 59 [200/1593 (13%)]\tLoss: 1.432704\n",
      "Train Epoch: 59 [300/1593 (19%)]\tLoss: 1.617782\n",
      "Train Epoch: 59 [400/1593 (25%)]\tLoss: 1.618224\n",
      "Train Epoch: 59 [500/1593 (31%)]\tLoss: 1.710648\n",
      "Train Epoch: 59 [600/1593 (38%)]\tLoss: 1.438934\n",
      "Train Epoch: 59 [700/1593 (44%)]\tLoss: 1.814511\n",
      "Train Epoch: 59 [800/1593 (50%)]\tLoss: 1.443890\n",
      "Train Epoch: 59 [900/1593 (56%)]\tLoss: 1.780009\n",
      "Train Epoch: 59 [1000/1593 (63%)]\tLoss: 1.815229\n",
      "Train Epoch: 59 [1100/1593 (69%)]\tLoss: 1.917890\n",
      "Train Epoch: 59 [1200/1593 (75%)]\tLoss: 1.540835\n",
      "Train Epoch: 59 [1300/1593 (82%)]\tLoss: 1.567121\n",
      "Train Epoch: 59 [1400/1593 (88%)]\tLoss: 2.065601\n",
      "Train Epoch: 59 [1500/1593 (94%)]\tLoss: 1.598265\n",
      "Train Epoch: 60 [0/1593 (0%)]\tLoss: 1.577122\n",
      "Train Epoch: 60 [100/1593 (6%)]\tLoss: 1.434184\n",
      "Train Epoch: 60 [200/1593 (13%)]\tLoss: 2.131490\n",
      "Train Epoch: 60 [300/1593 (19%)]\tLoss: 1.571324\n",
      "Train Epoch: 60 [400/1593 (25%)]\tLoss: 1.399340\n",
      "Train Epoch: 60 [500/1593 (31%)]\tLoss: 1.498841\n",
      "Train Epoch: 60 [600/1593 (38%)]\tLoss: 1.449623\n",
      "Train Epoch: 60 [700/1593 (44%)]\tLoss: 1.818665\n",
      "Train Epoch: 60 [800/1593 (50%)]\tLoss: 2.077184\n",
      "Train Epoch: 60 [900/1593 (56%)]\tLoss: 1.423667\n",
      "Train Epoch: 60 [1000/1593 (63%)]\tLoss: 1.758543\n",
      "Train Epoch: 60 [1100/1593 (69%)]\tLoss: 1.229136\n",
      "Train Epoch: 60 [1200/1593 (75%)]\tLoss: 1.249163\n",
      "Train Epoch: 60 [1300/1593 (82%)]\tLoss: 1.589474\n",
      "Train Epoch: 60 [1400/1593 (88%)]\tLoss: 1.557057\n",
      "Train Epoch: 60 [1500/1593 (94%)]\tLoss: 1.568155\n",
      "Train Epoch: 61 [0/1593 (0%)]\tLoss: 1.312176\n",
      "Train Epoch: 61 [100/1593 (6%)]\tLoss: 1.539638\n",
      "Train Epoch: 61 [200/1593 (13%)]\tLoss: 1.826663\n",
      "Train Epoch: 61 [300/1593 (19%)]\tLoss: 1.679332\n",
      "Train Epoch: 61 [400/1593 (25%)]\tLoss: 1.962864\n",
      "Train Epoch: 61 [500/1593 (31%)]\tLoss: 1.281850\n",
      "Train Epoch: 61 [600/1593 (38%)]\tLoss: 1.569102\n",
      "Train Epoch: 61 [700/1593 (44%)]\tLoss: 1.521584\n",
      "Train Epoch: 61 [800/1593 (50%)]\tLoss: 1.522707\n",
      "Train Epoch: 61 [900/1593 (56%)]\tLoss: 1.774982\n",
      "Train Epoch: 61 [1000/1593 (63%)]\tLoss: 1.503717\n",
      "Train Epoch: 61 [1100/1593 (69%)]\tLoss: 1.042489\n",
      "Train Epoch: 61 [1200/1593 (75%)]\tLoss: 1.796424\n",
      "Train Epoch: 61 [1300/1593 (82%)]\tLoss: 1.201421\n",
      "Train Epoch: 61 [1400/1593 (88%)]\tLoss: 2.035037\n",
      "Train Epoch: 61 [1500/1593 (94%)]\tLoss: 1.752012\n",
      "Train Epoch: 62 [0/1593 (0%)]\tLoss: 1.260985\n",
      "Train Epoch: 62 [100/1593 (6%)]\tLoss: 1.400723\n",
      "Train Epoch: 62 [200/1593 (13%)]\tLoss: 1.252263\n",
      "Train Epoch: 62 [300/1593 (19%)]\tLoss: 1.424086\n",
      "Train Epoch: 62 [400/1593 (25%)]\tLoss: 2.138962\n",
      "Train Epoch: 62 [500/1593 (31%)]\tLoss: 1.366941\n",
      "Train Epoch: 62 [600/1593 (38%)]\tLoss: 1.447149\n",
      "Train Epoch: 62 [700/1593 (44%)]\tLoss: 1.204901\n",
      "Train Epoch: 62 [800/1593 (50%)]\tLoss: 1.151319\n",
      "Train Epoch: 62 [900/1593 (56%)]\tLoss: 1.586571\n",
      "Train Epoch: 62 [1000/1593 (63%)]\tLoss: 1.358184\n",
      "Train Epoch: 62 [1100/1593 (69%)]\tLoss: 1.272063\n",
      "Train Epoch: 62 [1200/1593 (75%)]\tLoss: 1.059166\n",
      "Train Epoch: 62 [1300/1593 (82%)]\tLoss: 1.867999\n",
      "Train Epoch: 62 [1400/1593 (88%)]\tLoss: 2.200344\n",
      "Train Epoch: 62 [1500/1593 (94%)]\tLoss: 1.716115\n",
      "Train Epoch: 63 [0/1593 (0%)]\tLoss: 1.481400\n",
      "Train Epoch: 63 [100/1593 (6%)]\tLoss: 1.626980\n",
      "Train Epoch: 63 [200/1593 (13%)]\tLoss: 1.894536\n",
      "Train Epoch: 63 [300/1593 (19%)]\tLoss: 1.326697\n",
      "Train Epoch: 63 [400/1593 (25%)]\tLoss: 1.340366\n",
      "Train Epoch: 63 [500/1593 (31%)]\tLoss: 1.396000\n",
      "Train Epoch: 63 [600/1593 (38%)]\tLoss: 1.558017\n",
      "Train Epoch: 63 [700/1593 (44%)]\tLoss: 1.105184\n",
      "Train Epoch: 63 [800/1593 (50%)]\tLoss: 4.054114\n",
      "Train Epoch: 63 [900/1593 (56%)]\tLoss: 2.041263\n",
      "Train Epoch: 63 [1000/1593 (63%)]\tLoss: 1.397662\n",
      "Train Epoch: 63 [1100/1593 (69%)]\tLoss: 1.499531\n",
      "Train Epoch: 63 [1200/1593 (75%)]\tLoss: 1.422637\n",
      "Train Epoch: 63 [1300/1593 (82%)]\tLoss: 1.296060\n",
      "Train Epoch: 63 [1400/1593 (88%)]\tLoss: 1.639683\n",
      "Train Epoch: 63 [1500/1593 (94%)]\tLoss: 1.829528\n",
      "Train Epoch: 64 [0/1593 (0%)]\tLoss: 2.276885\n",
      "Train Epoch: 64 [100/1593 (6%)]\tLoss: 1.519043\n",
      "Train Epoch: 64 [200/1593 (13%)]\tLoss: 1.638627\n",
      "Train Epoch: 64 [300/1593 (19%)]\tLoss: 1.330660\n",
      "Train Epoch: 64 [400/1593 (25%)]\tLoss: 1.651224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 64 [500/1593 (31%)]\tLoss: 1.553845\n",
      "Train Epoch: 64 [600/1593 (38%)]\tLoss: 1.411383\n",
      "Train Epoch: 64 [700/1593 (44%)]\tLoss: 1.176699\n",
      "Train Epoch: 64 [800/1593 (50%)]\tLoss: 1.796999\n",
      "Train Epoch: 64 [900/1593 (56%)]\tLoss: 1.251201\n",
      "Train Epoch: 64 [1000/1593 (63%)]\tLoss: 1.566220\n",
      "Train Epoch: 64 [1100/1593 (69%)]\tLoss: 1.581422\n",
      "Train Epoch: 64 [1200/1593 (75%)]\tLoss: 1.345609\n",
      "Train Epoch: 64 [1300/1593 (82%)]\tLoss: 1.280065\n",
      "Train Epoch: 64 [1400/1593 (88%)]\tLoss: 1.563831\n",
      "Train Epoch: 64 [1500/1593 (94%)]\tLoss: 1.612743\n",
      "Train Epoch: 65 [0/1593 (0%)]\tLoss: 1.871540\n",
      "Train Epoch: 65 [100/1593 (6%)]\tLoss: 1.659234\n",
      "Train Epoch: 65 [200/1593 (13%)]\tLoss: 1.647990\n",
      "Train Epoch: 65 [300/1593 (19%)]\tLoss: 1.278894\n",
      "Train Epoch: 65 [400/1593 (25%)]\tLoss: 1.485899\n",
      "Train Epoch: 65 [500/1593 (31%)]\tLoss: 1.639910\n",
      "Train Epoch: 65 [600/1593 (38%)]\tLoss: 1.429198\n",
      "Train Epoch: 65 [700/1593 (44%)]\tLoss: 1.699653\n",
      "Train Epoch: 65 [800/1593 (50%)]\tLoss: 1.605219\n",
      "Train Epoch: 65 [900/1593 (56%)]\tLoss: 1.306348\n",
      "Train Epoch: 65 [1000/1593 (63%)]\tLoss: 1.332095\n",
      "Train Epoch: 65 [1100/1593 (69%)]\tLoss: 1.437847\n",
      "Train Epoch: 65 [1200/1593 (75%)]\tLoss: 1.162405\n",
      "Train Epoch: 65 [1300/1593 (82%)]\tLoss: 1.615661\n",
      "Train Epoch: 65 [1400/1593 (88%)]\tLoss: 1.224316\n",
      "Train Epoch: 65 [1500/1593 (94%)]\tLoss: 1.184376\n",
      "Train Epoch: 66 [0/1593 (0%)]\tLoss: 1.468277\n",
      "Train Epoch: 66 [100/1593 (6%)]\tLoss: 1.545444\n",
      "Train Epoch: 66 [200/1593 (13%)]\tLoss: 1.650328\n",
      "Train Epoch: 66 [300/1593 (19%)]\tLoss: 1.854842\n",
      "Train Epoch: 66 [400/1593 (25%)]\tLoss: 1.565176\n",
      "Train Epoch: 66 [500/1593 (31%)]\tLoss: 2.005075\n",
      "Train Epoch: 66 [600/1593 (38%)]\tLoss: 1.556976\n",
      "Train Epoch: 66 [700/1593 (44%)]\tLoss: 1.355046\n",
      "Train Epoch: 66 [800/1593 (50%)]\tLoss: 1.589623\n",
      "Train Epoch: 66 [900/1593 (56%)]\tLoss: 1.307190\n",
      "Train Epoch: 66 [1000/1593 (63%)]\tLoss: 1.443402\n",
      "Train Epoch: 66 [1100/1593 (69%)]\tLoss: 1.859558\n",
      "Train Epoch: 66 [1200/1593 (75%)]\tLoss: 1.508818\n",
      "Train Epoch: 66 [1300/1593 (82%)]\tLoss: 1.905890\n",
      "Train Epoch: 66 [1400/1593 (88%)]\tLoss: 1.185865\n",
      "Train Epoch: 66 [1500/1593 (94%)]\tLoss: 1.731790\n",
      "Train Epoch: 67 [0/1593 (0%)]\tLoss: 1.430793\n",
      "Train Epoch: 67 [100/1593 (6%)]\tLoss: 1.535933\n",
      "Train Epoch: 67 [200/1593 (13%)]\tLoss: 1.497939\n",
      "Train Epoch: 67 [300/1593 (19%)]\tLoss: 2.061117\n",
      "Train Epoch: 67 [400/1593 (25%)]\tLoss: 1.429087\n",
      "Train Epoch: 67 [500/1593 (31%)]\tLoss: 1.541972\n",
      "Train Epoch: 67 [600/1593 (38%)]\tLoss: 1.850206\n",
      "Train Epoch: 67 [700/1593 (44%)]\tLoss: 1.752536\n",
      "Train Epoch: 67 [800/1593 (50%)]\tLoss: 1.583065\n",
      "Train Epoch: 67 [900/1593 (56%)]\tLoss: 1.598914\n",
      "Train Epoch: 67 [1000/1593 (63%)]\tLoss: 1.148317\n",
      "Train Epoch: 67 [1100/1593 (69%)]\tLoss: 0.935697\n",
      "Train Epoch: 67 [1200/1593 (75%)]\tLoss: 1.441849\n",
      "Train Epoch: 67 [1300/1593 (82%)]\tLoss: 1.799951\n",
      "Train Epoch: 67 [1400/1593 (88%)]\tLoss: 1.480124\n",
      "Train Epoch: 67 [1500/1593 (94%)]\tLoss: 1.134187\n",
      "Train Epoch: 68 [0/1593 (0%)]\tLoss: 0.950758\n",
      "Train Epoch: 68 [100/1593 (6%)]\tLoss: 1.452228\n",
      "Train Epoch: 68 [200/1593 (13%)]\tLoss: 1.320243\n",
      "Train Epoch: 68 [300/1593 (19%)]\tLoss: 2.094594\n",
      "Train Epoch: 68 [400/1593 (25%)]\tLoss: 1.453693\n",
      "Train Epoch: 68 [500/1593 (31%)]\tLoss: 1.286006\n",
      "Train Epoch: 68 [600/1593 (38%)]\tLoss: 1.683975\n",
      "Train Epoch: 68 [700/1593 (44%)]\tLoss: 2.249817\n",
      "Train Epoch: 68 [800/1593 (50%)]\tLoss: 1.688854\n",
      "Train Epoch: 68 [900/1593 (56%)]\tLoss: 1.840373\n",
      "Train Epoch: 68 [1000/1593 (63%)]\tLoss: 1.299997\n",
      "Train Epoch: 68 [1100/1593 (69%)]\tLoss: 1.320362\n",
      "Train Epoch: 68 [1200/1593 (75%)]\tLoss: 1.079232\n",
      "Train Epoch: 68 [1300/1593 (82%)]\tLoss: 1.473997\n",
      "Train Epoch: 68 [1400/1593 (88%)]\tLoss: 1.384274\n",
      "Train Epoch: 68 [1500/1593 (94%)]\tLoss: 1.796461\n",
      "Train Epoch: 69 [0/1593 (0%)]\tLoss: 1.568827\n",
      "Train Epoch: 69 [100/1593 (6%)]\tLoss: 1.507606\n",
      "Train Epoch: 69 [200/1593 (13%)]\tLoss: 1.716243\n",
      "Train Epoch: 69 [300/1593 (19%)]\tLoss: 1.502806\n",
      "Train Epoch: 69 [400/1593 (25%)]\tLoss: 1.763199\n",
      "Train Epoch: 69 [500/1593 (31%)]\tLoss: 1.550115\n",
      "Train Epoch: 69 [600/1593 (38%)]\tLoss: 1.607699\n",
      "Train Epoch: 69 [700/1593 (44%)]\tLoss: 1.459614\n",
      "Train Epoch: 69 [800/1593 (50%)]\tLoss: 1.182687\n",
      "Train Epoch: 69 [900/1593 (56%)]\tLoss: 1.435101\n",
      "Train Epoch: 69 [1000/1593 (63%)]\tLoss: 1.697913\n",
      "Train Epoch: 69 [1100/1593 (69%)]\tLoss: 1.621756\n",
      "Train Epoch: 69 [1200/1593 (75%)]\tLoss: 1.476312\n",
      "Train Epoch: 69 [1300/1593 (82%)]\tLoss: 1.398743\n",
      "Train Epoch: 69 [1400/1593 (88%)]\tLoss: 1.386933\n",
      "Train Epoch: 69 [1500/1593 (94%)]\tLoss: 1.423917\n",
      "Train Epoch: 70 [0/1593 (0%)]\tLoss: 1.518260\n",
      "Train Epoch: 70 [100/1593 (6%)]\tLoss: 1.424620\n",
      "Train Epoch: 70 [200/1593 (13%)]\tLoss: 1.758690\n",
      "Train Epoch: 70 [300/1593 (19%)]\tLoss: 1.169184\n",
      "Train Epoch: 70 [400/1593 (25%)]\tLoss: 2.097846\n",
      "Train Epoch: 70 [500/1593 (31%)]\tLoss: 1.546584\n",
      "Train Epoch: 70 [600/1593 (38%)]\tLoss: 1.423306\n",
      "Train Epoch: 70 [700/1593 (44%)]\tLoss: 1.280645\n",
      "Train Epoch: 70 [800/1593 (50%)]\tLoss: 1.458343\n",
      "Train Epoch: 70 [900/1593 (56%)]\tLoss: 1.430173\n",
      "Train Epoch: 70 [1000/1593 (63%)]\tLoss: 1.715001\n",
      "Train Epoch: 70 [1100/1593 (69%)]\tLoss: 1.288413\n",
      "Train Epoch: 70 [1200/1593 (75%)]\tLoss: 1.555421\n",
      "Train Epoch: 70 [1300/1593 (82%)]\tLoss: 1.265662\n",
      "Train Epoch: 70 [1400/1593 (88%)]\tLoss: 1.254658\n",
      "Train Epoch: 70 [1500/1593 (94%)]\tLoss: 1.341077\n",
      "Train Epoch: 71 [0/1593 (0%)]\tLoss: 1.332850\n",
      "Train Epoch: 71 [100/1593 (6%)]\tLoss: 1.334417\n",
      "Train Epoch: 71 [200/1593 (13%)]\tLoss: 1.500640\n",
      "Train Epoch: 71 [300/1593 (19%)]\tLoss: 1.463992\n",
      "Train Epoch: 71 [400/1593 (25%)]\tLoss: 1.376756\n",
      "Train Epoch: 71 [500/1593 (31%)]\tLoss: 1.367469\n",
      "Train Epoch: 71 [600/1593 (38%)]\tLoss: 1.315144\n",
      "Train Epoch: 71 [700/1593 (44%)]\tLoss: 1.314011\n",
      "Train Epoch: 71 [800/1593 (50%)]\tLoss: 1.792809\n",
      "Train Epoch: 71 [900/1593 (56%)]\tLoss: 1.622153\n",
      "Train Epoch: 71 [1000/1593 (63%)]\tLoss: 1.579251\n",
      "Train Epoch: 71 [1100/1593 (69%)]\tLoss: 1.314804\n",
      "Train Epoch: 71 [1200/1593 (75%)]\tLoss: 1.518559\n",
      "Train Epoch: 71 [1300/1593 (82%)]\tLoss: 1.381499\n",
      "Train Epoch: 71 [1400/1593 (88%)]\tLoss: 1.514122\n",
      "Train Epoch: 71 [1500/1593 (94%)]\tLoss: 1.268713\n",
      "Train Epoch: 72 [0/1593 (0%)]\tLoss: 1.326431\n",
      "Train Epoch: 72 [100/1593 (6%)]\tLoss: 1.939655\n",
      "Train Epoch: 72 [200/1593 (13%)]\tLoss: 1.215806\n",
      "Train Epoch: 72 [300/1593 (19%)]\tLoss: 1.270350\n",
      "Train Epoch: 72 [400/1593 (25%)]\tLoss: 1.425817\n",
      "Train Epoch: 72 [500/1593 (31%)]\tLoss: 1.436345\n",
      "Train Epoch: 72 [600/1593 (38%)]\tLoss: 1.718128\n",
      "Train Epoch: 72 [700/1593 (44%)]\tLoss: 1.373751\n",
      "Train Epoch: 72 [800/1593 (50%)]\tLoss: 1.693457\n",
      "Train Epoch: 72 [900/1593 (56%)]\tLoss: 1.417062\n",
      "Train Epoch: 72 [1000/1593 (63%)]\tLoss: 1.161632\n",
      "Train Epoch: 72 [1100/1593 (69%)]\tLoss: 1.750583\n",
      "Train Epoch: 72 [1200/1593 (75%)]\tLoss: 1.588434\n",
      "Train Epoch: 72 [1300/1593 (82%)]\tLoss: 1.221181\n",
      "Train Epoch: 72 [1400/1593 (88%)]\tLoss: 1.346849\n",
      "Train Epoch: 72 [1500/1593 (94%)]\tLoss: 1.612608\n",
      "Train Epoch: 73 [0/1593 (0%)]\tLoss: 1.358730\n",
      "Train Epoch: 73 [100/1593 (6%)]\tLoss: 1.115062\n",
      "Train Epoch: 73 [200/1593 (13%)]\tLoss: 1.489609\n",
      "Train Epoch: 73 [300/1593 (19%)]\tLoss: 2.170883\n",
      "Train Epoch: 73 [400/1593 (25%)]\tLoss: 1.390541\n",
      "Train Epoch: 73 [500/1593 (31%)]\tLoss: 1.581293\n",
      "Train Epoch: 73 [600/1593 (38%)]\tLoss: 1.546417\n",
      "Train Epoch: 73 [700/1593 (44%)]\tLoss: 1.665746\n",
      "Train Epoch: 73 [800/1593 (50%)]\tLoss: 1.323837\n",
      "Train Epoch: 73 [900/1593 (56%)]\tLoss: 1.313788\n",
      "Train Epoch: 73 [1000/1593 (63%)]\tLoss: 1.577240\n",
      "Train Epoch: 73 [1100/1593 (69%)]\tLoss: 1.459620\n",
      "Train Epoch: 73 [1200/1593 (75%)]\tLoss: 2.050800\n",
      "Train Epoch: 73 [1300/1593 (82%)]\tLoss: 1.285426\n",
      "Train Epoch: 73 [1400/1593 (88%)]\tLoss: 1.514193\n",
      "Train Epoch: 73 [1500/1593 (94%)]\tLoss: 1.756942\n",
      "Train Epoch: 74 [0/1593 (0%)]\tLoss: 1.646246\n",
      "Train Epoch: 74 [100/1593 (6%)]\tLoss: 1.393284\n",
      "Train Epoch: 74 [200/1593 (13%)]\tLoss: 1.372803\n",
      "Train Epoch: 74 [300/1593 (19%)]\tLoss: 1.344716\n",
      "Train Epoch: 74 [400/1593 (25%)]\tLoss: 1.457288\n",
      "Train Epoch: 74 [500/1593 (31%)]\tLoss: 1.316691\n",
      "Train Epoch: 74 [600/1593 (38%)]\tLoss: 1.590713\n",
      "Train Epoch: 74 [700/1593 (44%)]\tLoss: 1.339735\n",
      "Train Epoch: 74 [800/1593 (50%)]\tLoss: 1.292916\n",
      "Train Epoch: 74 [900/1593 (56%)]\tLoss: 1.617586\n",
      "Train Epoch: 74 [1000/1593 (63%)]\tLoss: 1.392387\n",
      "Train Epoch: 74 [1100/1593 (69%)]\tLoss: 1.629784\n",
      "Train Epoch: 74 [1200/1593 (75%)]\tLoss: 1.137968\n",
      "Train Epoch: 74 [1300/1593 (82%)]\tLoss: 1.427384\n",
      "Train Epoch: 74 [1400/1593 (88%)]\tLoss: 1.280517\n",
      "Train Epoch: 74 [1500/1593 (94%)]\tLoss: 1.276130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 75 [0/1593 (0%)]\tLoss: 1.420161\n",
      "Train Epoch: 75 [100/1593 (6%)]\tLoss: 1.393553\n",
      "Train Epoch: 75 [200/1593 (13%)]\tLoss: 1.589228\n",
      "Train Epoch: 75 [300/1593 (19%)]\tLoss: 1.306402\n",
      "Train Epoch: 75 [400/1593 (25%)]\tLoss: 1.554134\n",
      "Train Epoch: 75 [500/1593 (31%)]\tLoss: 1.509404\n",
      "Train Epoch: 75 [600/1593 (38%)]\tLoss: 1.630840\n",
      "Train Epoch: 75 [700/1593 (44%)]\tLoss: 1.359795\n",
      "Train Epoch: 75 [800/1593 (50%)]\tLoss: 1.226352\n",
      "Train Epoch: 75 [900/1593 (56%)]\tLoss: 1.306952\n",
      "Train Epoch: 75 [1000/1593 (63%)]\tLoss: 1.457082\n",
      "Train Epoch: 75 [1100/1593 (69%)]\tLoss: 1.149705\n",
      "Train Epoch: 75 [1200/1593 (75%)]\tLoss: 1.293676\n",
      "Train Epoch: 75 [1300/1593 (82%)]\tLoss: 1.399068\n",
      "Train Epoch: 75 [1400/1593 (88%)]\tLoss: 1.553788\n",
      "Train Epoch: 75 [1500/1593 (94%)]\tLoss: 1.507393\n",
      "Train Epoch: 76 [0/1593 (0%)]\tLoss: 0.930600\n",
      "Train Epoch: 76 [100/1593 (6%)]\tLoss: 1.552244\n",
      "Train Epoch: 76 [200/1593 (13%)]\tLoss: 1.457642\n",
      "Train Epoch: 76 [300/1593 (19%)]\tLoss: 1.244537\n",
      "Train Epoch: 76 [400/1593 (25%)]\tLoss: 1.387221\n",
      "Train Epoch: 76 [500/1593 (31%)]\tLoss: 1.737312\n",
      "Train Epoch: 76 [600/1593 (38%)]\tLoss: 1.822777\n",
      "Train Epoch: 76 [700/1593 (44%)]\tLoss: 1.313716\n",
      "Train Epoch: 76 [800/1593 (50%)]\tLoss: 1.941412\n",
      "Train Epoch: 76 [900/1593 (56%)]\tLoss: 1.261130\n",
      "Train Epoch: 76 [1000/1593 (63%)]\tLoss: 1.068378\n",
      "Train Epoch: 76 [1100/1593 (69%)]\tLoss: 1.434796\n",
      "Train Epoch: 76 [1200/1593 (75%)]\tLoss: 1.724746\n",
      "Train Epoch: 76 [1300/1593 (82%)]\tLoss: 1.532635\n",
      "Train Epoch: 76 [1400/1593 (88%)]\tLoss: 1.842141\n",
      "Train Epoch: 76 [1500/1593 (94%)]\tLoss: 1.300016\n",
      "Train Epoch: 77 [0/1593 (0%)]\tLoss: 1.967836\n",
      "Train Epoch: 77 [100/1593 (6%)]\tLoss: 1.186635\n",
      "Train Epoch: 77 [200/1593 (13%)]\tLoss: 1.239149\n",
      "Train Epoch: 77 [300/1593 (19%)]\tLoss: 1.601408\n",
      "Train Epoch: 77 [400/1593 (25%)]\tLoss: 1.673869\n",
      "Train Epoch: 77 [500/1593 (31%)]\tLoss: 1.586663\n",
      "Train Epoch: 77 [600/1593 (38%)]\tLoss: 1.482338\n",
      "Train Epoch: 77 [700/1593 (44%)]\tLoss: 1.745750\n",
      "Train Epoch: 77 [800/1593 (50%)]\tLoss: 1.209320\n",
      "Train Epoch: 77 [900/1593 (56%)]\tLoss: 1.073195\n",
      "Train Epoch: 77 [1000/1593 (63%)]\tLoss: 1.451893\n",
      "Train Epoch: 77 [1100/1593 (69%)]\tLoss: 1.323565\n",
      "Train Epoch: 77 [1200/1593 (75%)]\tLoss: 1.874065\n",
      "Train Epoch: 77 [1300/1593 (82%)]\tLoss: 1.714719\n",
      "Train Epoch: 77 [1400/1593 (88%)]\tLoss: 1.673839\n",
      "Train Epoch: 77 [1500/1593 (94%)]\tLoss: 1.537132\n",
      "Train Epoch: 78 [0/1593 (0%)]\tLoss: 1.624656\n",
      "Train Epoch: 78 [100/1593 (6%)]\tLoss: 1.705365\n",
      "Train Epoch: 78 [200/1593 (13%)]\tLoss: 1.293975\n",
      "Train Epoch: 78 [300/1593 (19%)]\tLoss: 1.186398\n",
      "Train Epoch: 78 [400/1593 (25%)]\tLoss: 1.538647\n",
      "Train Epoch: 78 [500/1593 (31%)]\tLoss: 1.356953\n",
      "Train Epoch: 78 [600/1593 (38%)]\tLoss: 1.523942\n",
      "Train Epoch: 78 [700/1593 (44%)]\tLoss: 1.195298\n",
      "Train Epoch: 78 [800/1593 (50%)]\tLoss: 1.268937\n",
      "Train Epoch: 78 [900/1593 (56%)]\tLoss: 1.807743\n",
      "Train Epoch: 78 [1000/1593 (63%)]\tLoss: 1.901640\n",
      "Train Epoch: 78 [1100/1593 (69%)]\tLoss: 1.373986\n",
      "Train Epoch: 78 [1200/1593 (75%)]\tLoss: 1.282301\n",
      "Train Epoch: 78 [1300/1593 (82%)]\tLoss: 1.411535\n",
      "Train Epoch: 78 [1400/1593 (88%)]\tLoss: 1.757053\n",
      "Train Epoch: 78 [1500/1593 (94%)]\tLoss: 1.618397\n",
      "Train Epoch: 79 [0/1593 (0%)]\tLoss: 1.706378\n",
      "Train Epoch: 79 [100/1593 (6%)]\tLoss: 1.307819\n",
      "Train Epoch: 79 [200/1593 (13%)]\tLoss: 1.374385\n",
      "Train Epoch: 79 [300/1593 (19%)]\tLoss: 1.398383\n",
      "Train Epoch: 79 [400/1593 (25%)]\tLoss: 1.722191\n",
      "Train Epoch: 79 [500/1593 (31%)]\tLoss: 1.504128\n",
      "Train Epoch: 79 [600/1593 (38%)]\tLoss: 1.277843\n",
      "Train Epoch: 79 [700/1593 (44%)]\tLoss: 1.695267\n",
      "Train Epoch: 79 [800/1593 (50%)]\tLoss: 1.588155\n",
      "Train Epoch: 79 [900/1593 (56%)]\tLoss: 1.484282\n",
      "Train Epoch: 79 [1000/1593 (63%)]\tLoss: 1.984248\n",
      "Train Epoch: 79 [1100/1593 (69%)]\tLoss: 1.186653\n",
      "Train Epoch: 79 [1200/1593 (75%)]\tLoss: 1.589533\n",
      "Train Epoch: 79 [1300/1593 (82%)]\tLoss: 1.350489\n",
      "Train Epoch: 79 [1400/1593 (88%)]\tLoss: 1.393123\n",
      "Train Epoch: 79 [1500/1593 (94%)]\tLoss: 1.466326\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "data_len = len(train_loader.dataset)\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, _data in enumerate(train_loader):\n",
    "        file_id, ema, labels, input_lengths, label_lengths = _data \n",
    "        ema, labels = ema.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        h, c = model.init_hidden(ema)\n",
    "        h, c = h.to(device), c.to(device)\n",
    "\n",
    "        output = model(ema, h, c)  # (batch, time, n_class)\n",
    "        \n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        iter_meter.step()\n",
    "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(ema), data_len,\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63dc9722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "3.149390243902439\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = []\n",
    "label = []\n",
    "\n",
    "from jiwer import wer\n",
    "\n",
    "for batch_idx, _data in enumerate(test_loader):\n",
    "    fid, ema, labels, input_lengths, label_lengths = _data \n",
    "    ema, labels = ema.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    h, c = model.init_hidden(ema)\n",
    "    h, c = h.to(device), c.to(device)\n",
    "\n",
    "    output = model(ema, h, c)  # (batch, time, n_class)\n",
    "\n",
    "    output = F.log_softmax(output, dim=2)\n",
    "    output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "    \n",
    "    loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "  #  test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "    decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "\n",
    "    \n",
    "    pred.append(' '.join(decoded_preds[0]))\n",
    "    label.append(' '.join(decoded_targets[0]))\n",
    "    \n",
    "print(len(pred))\n",
    "print(len(label))\n",
    "\n",
    "error = wer(pred, label)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b48bca51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AY L L EY\n",
      "SP S M OW K IY F AY ER Z L AE K F L EY M AE N D SP SHH IY T SP\n",
      "#####################\n",
      "AH K EY R M DH\n",
      "SP DH AH S AO L T B R IY Z K EY M AH K R AO S F ER M DH AH S IY SP\n",
      "#####################\n",
      "AH L D R K R S ER M DH DH\n",
      "SP DH AH S AO L T B R IY Z K EY M SP AH K R AO S F ER M DH AH S IY SP\n",
      "#####################\n",
      "DH AH R K R AO S ER AH M DH DH\n",
      "SP DH AH S AO L T B R IY Z K EY M AH K R AO S F ER M DH AH S IY SP\n",
      "#####################\n",
      "AH OW DH AH AH L AH AH P N\n",
      "SP DH AH G ER L AE T DH AH B UW TH S OW L D F IH F T IY B   N D Z SP\n",
      "#####################\n",
      "AH ER AH AH DH L V\n",
      "SP DH AH G ER L AE T DH AH B UW TH S OW L D F IH F T IY B   N D Z SP\n",
      "#####################\n",
      "AH ER AH DH L AH\n",
      "SP DH AH G ER L AE T DH AH B UW TH S OW L D F IH F T IY B   N D Z SP\n",
      "#####################\n",
      "DH AH M N L S S\n",
      "SP DH AH S M AO L P AH P N AO D AH SHH OW L IH N DH AH S   K SP\n",
      "#####################\n",
      "AH N DH AH S\n",
      "SP DH AH S M AO L P AH P SP N AO D AH SHH OW L IH N DH AH S   K SP\n",
      "#####################\n",
      "DH AH N L DH AH S S\n",
      "SP DH AH S M AO L P AH P N AO D AH SHH OW L IH N DH AH S   K SP\n",
      "#####################\n",
      "AH W IH DH AH EH\n",
      "SP DH AH F IH SH T W IH S T AH D AH N D T ER N D   N DH AH B EH N T SHH UH K SP\n",
      "#####################\n",
      "AH W T AH\n",
      "SP DH AH F IH SH SP T W IH S T AH D AE N D T ER N D   N DH AH B EH N T SHH UH K SP\n",
      "#####################\n",
      "AH W AH\n",
      "SP DH AH F IH SH T W IH S T AH D AE N D T ER N D   N DH AH B EH N T SHH UH K SP\n",
      "#####################\n",
      "S AH OW DH AH S\n",
      "SP P R EH S DH AH P AE N T S AH N D S OW AH B AH T AH N   N DH AH V EH S T SP\n",
      "#####################\n",
      "R DH AH S AH S\n",
      "SP P R EH S DH AH P AE N T S AH N D S OW AH B AH T AH N   N DH AH V EH S T SP\n",
      "#####################\n",
      "R DH AH N S AH AH S\n",
      "SP P R EH S DH AH P AE N T S SP AE N D S OW AH B AH T AH N   N DH AH V EH S T SP\n",
      "#####################\n",
      "  R AO R ER R IH\n",
      "SP DH AH S W   N D AY V W AH Z F   R SH AO R T AH V P ER F IH K T SP\n",
      "#####################\n",
      "DH W W AH Z   R R R AH IH\n",
      "SP DH AH S W   N D AY V W AH Z F   R SH AO R T AH V P ER F EH K T SP\n",
      "#####################\n",
      "DH W AH   R AO R AH ER IH\n",
      "SP DH AH S W   N D AY V W AH Z F   R SH AO R T AH V P ER F IH K T SP\n",
      "#####################\n",
      "AH V AH DH OY\n",
      "SP DH AH B Y UW T IY AH V DH AH V Y UW S T AH N D DH IY Y AH NG B OY SP\n",
      "#####################\n",
      "AH V DH OY\n",
      "SP DH AH B Y UW T IY AH V DH AH V Y UW SP S T AH N D DH IY Y AH NG B OY SP\n",
      "#####################\n",
      "AH V AH UW T AH DH OY\n",
      "SP DH AH B Y UW T IY AH V DH AH V Y UW S T AH N D DH IY Y AH NG B OY SP\n",
      "#####################\n",
      "UW P L AH W P AH DH AH\n",
      "SP T UW B L UW F IH SH S W AE M AH N DH AH T AE NG K SP\n",
      "#####################\n",
      "UW W P DH AH\n",
      "SP T UW B L UW F IH SH S W AE M IH N DH AH T AE NG K SP\n",
      "#####################\n",
      "UW P L W DH AH\n",
      "SP T UW B L UW F IH SH SP S W AE M AH N DH AH T AE NG K SP\n",
      "#####################\n",
      "AH L UW L S T R\n",
      "SP SHH ER P ER S W AH Z F UH L AH V Y UW S L AH S T R AE SH SP\n",
      "#####################\n",
      "R S W AH AH T R\n",
      "SP SHH ER P ER S W AH Z F UH L AH V Y UW S L AH S T R AE SH SP\n",
      "#####################\n",
      "R AH AH L L V R\n",
      "SP SHH ER P ER S W AH Z F UH L AH V Y UW S L AH S T R AE SH SP\n",
      "#####################\n",
      "AH R R\n",
      "SP DH AH K OW L T R IH R D AH N D TH R UW DH AH T AO L R AY D ER SP\n",
      "#####################\n",
      "AH L L R R R AY\n",
      "SP DH AH K OW L T R IH R D AE N D TH R UW DH AH T AO L R AY D ER SP\n",
      "#####################\n",
      "AH L R R R AY\n",
      "SP DH AH K OW L T R IH R D AE N D TH R UW DH AH T AO L R AY D ER SP\n",
      "#####################\n",
      "OW R L DH AH AO\n",
      "SP IH T S N OW D R EY N D AE N D SHH EY L D DH AH S EY M M AO R N IH NG SP\n",
      "#####################\n",
      "IH OW AH R L DH AO R AY\n",
      "SP IH T S N OW D R EY N D AE N D SHH EY L D DH AH S EY M M AO R N IH NG SP\n",
      "#####################\n",
      "OW AH R DH AH S AO R\n",
      "SP IH T S N OW D R EY N D AE N D SHH EY L D DH AH S EY M M AO R N IH NG SP\n",
      "#####################\n",
      "IY IY L P\n",
      "SP R IY D V ER S AW T L AW D F ER P L EH ZH ER SP\n",
      "#####################\n",
      "IY AW L AW\n",
      "SP R IY D V ER S AW T L AW D F ER P L EH ZH ER SP\n",
      "#####################\n",
      "S AW\n",
      "SP R IY D V ER S SP AW T L AW D F R ER P L EH ZH ER SP\n",
      "#####################\n",
      "OY DH L OW IH L\n",
      "SP SHH OY S T DH AH L OW D T IH Y UH R L EH F T SH OW L D ER SP\n",
      "#####################\n",
      "DH AH L L L F\n",
      "SP SHH OY S T DH AH L OW D T AH Y UH R L EH F T SH OW L D ER SP\n",
      "#####################\n",
      "DH AH OW L\n",
      "SP SHH OY S T DH AH L OW D T AH Y UH R L EH F T SH OW L D ER SP\n",
      "#####################\n",
      "DH AH W IY AH L L\n",
      "SP T EY K DH AH W AY N D IH NG P AE TH T IH R IY CH SP DH AH L EY K SP\n",
      "#####################\n",
      "AY DH AH W AY DH AH R IY AH L\n",
      "SP T EY K DH AH W AY N D IH NG P AE TH T UW R IY CH DH AH L EY K SP\n",
      "#####################\n",
      "AH W AY DH AH AH R IY AH\n",
      "SP T EY K DH AH W AY N D IH NG P AE TH SP T AH R IY CH DH AH L EY K SP\n",
      "#####################\n",
      "L L S V\n",
      "SP N OW T K L OW S L IY DH AH S AY Z AH V DH IY G AE S T AE NG K SP\n",
      "#####################\n",
      "N OW K L AH Z L AH V DH S\n",
      "SP N OW T K L OW S L IY DH AH S AY Z AH V DH IY G AE S T AE NG K SP\n",
      "#####################\n",
      "OW L L DH AH V S T\n",
      "SP N OW T K L OW S L IY DH AH S AY Z AH V DH AH G AE S T AE NG K SP\n",
      "#####################\n",
      "W DH AH R IY AH\n",
      "SP W AY P DH AH G R IY S AO F SHH AH Z D ER T IY F EY S SP\n",
      "#####################\n",
      "W AH R AH\n",
      "SP W AY P DH AH G R IY S AO F SHH AH Z D ER T IY F EY S SP\n",
      "#####################\n",
      "W AH R IY AH\n",
      "SP W AY P DH AH G R IY S AO F SHH AH Z D ER T IY F EY S SP\n",
      "#####################\n",
      "DH AH AO R R AW\n",
      "SP M EH N D DH AH K OW T B AH F AO R Y UW G OW AW T SP\n",
      "#####################\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pred)):\n",
    "    print(pred[i])\n",
    "    print(label[i])\n",
    "    print('#####################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3ba864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e25143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
